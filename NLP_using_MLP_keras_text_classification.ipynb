{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "902c2a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'지쿠터': 1, '횡단보도': 2, '지바이크': 3, '입니다': 4, '넘어졌어요': 5, '조심하세요': 6, '주차금지': 7}\n",
      "[[0. 1. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 1.]]\n",
      "[[0.   0.33 0.   0.33 0.33 0.   0.   0.  ]\n",
      " [0.   0.5  0.   0.   0.   0.5  0.   0.  ]\n",
      " [0.   0.   0.5  0.   0.   0.   0.5  0.  ]\n",
      " [0.   0.33 0.33 0.   0.   0.   0.   0.33]]\n",
      "[[0.   0.69 0.   1.1  1.1  0.   0.   0.  ]\n",
      " [0.   0.69 0.   0.   0.   1.1  0.   0.  ]\n",
      " [0.   0.   0.85 0.   0.   0.   1.1  0.  ]\n",
      " [0.   0.69 0.85 0.   0.   0.   0.   1.1 ]]\n"
     ]
    }
   ],
   "source": [
    "# 케라스 토크나이저 : texts_to_matrix() 테스트\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "texts = ['지바이크 지쿠터 입니다', '지쿠터 넘어졌어요', '횡단보도 조심하세요', '지쿠터 횡단보도 주차금지']\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "print(tokenizer.word_index)\n",
    "\n",
    "# 'count' --> (Document-Term Matrix, DTM)을 생성, DTM에서의 인덱스는 앞코드의 word_index의 결과\n",
    "print(tokenizer.texts_to_matrix(texts, mode = 'count')) # texts_to_matrix의 입력으로 texts를 넣고, 모드는 'count'\n",
    "print(tokenizer.texts_to_matrix(texts, mode = 'freq').round(2)) # 둘째 자리까지 반올림하여 출력\n",
    "print(tokenizer.texts_to_matrix(texts, mode = 'tfidf').round(2)) # 둘째 자리까지 반올림하여 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba41a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 데이터 : 20개 뉴스 그룹(Twenty Newsgroups) 이메일 데이터셋\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cac6a37e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n",
      "훈련용 샘플의 개수 : 11314\n",
      "총 주제의 개수 : 20\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "첫번째 샘플의 레이블 : 7\n",
      "7번 레이블이 의미하는 주제 : rec.autos\n",
      "첫번째 샘플의 내용 : From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newsdata = fetch_20newsgroups(subset = 'train') # 'train'을 기재하면 훈련 데이터만 리턴한다.\n",
    "print(newsdata.keys())\n",
    "print('훈련용 샘플의 개수 : {}'.format(len(newsdata.data)))\n",
    "print('총 주제의 개수 : {}'.format(len(newsdata.target_names)))\n",
    "print(newsdata.target_names)\n",
    "print('첫번째 샘플의 레이블 : {}'.format(newsdata.target[0]))\n",
    "print('7번 레이블이 의미하는 주제 : {}'.format(newsdata.target_names[7]))\n",
    "print('첫번째 샘플의 내용 : {}'.format(newsdata.data[0])) # 첫번째 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "736b1161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               email  target\n",
      "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
      "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n",
      "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n",
      "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
      "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11314 entries, 0 to 11313\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   email   11314 non-null  object\n",
      " 1   target  11314 non-null  int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 132.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data로부터 데이터프레임을 생성하고, target 열을 추가한 뒤에 상위 5개의 행을 출력\n",
    "data = pd.DataFrame(newsdata.data, columns = ['email'])\n",
    "data['target'] = pd.Series(newsdata.target)\n",
    "print(data[:5])\n",
    "data.info()\n",
    "\n",
    "# news열은 문자열, target열은 정수형 데이터\n",
    "# Null 값을 가진 샘플이 있는지 isnull().values.any() 확인\n",
    "data.isnull().values.any() # False : 데이터 Null 값 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1e8fd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복을 제외한 샘플의 수 : 11314\n",
      "중복을 제외한 주제의 수 : 20\n",
      "    target  count\n",
      "0        0    480\n",
      "1        1    584\n",
      "2        2    591\n",
      "3        3    590\n",
      "4        4    578\n",
      "5        5    593\n",
      "6        6    585\n",
      "7        7    594\n",
      "8        8    598\n",
      "9        9    597\n",
      "10      10    600\n",
      "11      11    595\n",
      "12      12    591\n",
      "13      13    594\n",
      "14      14    593\n",
      "15      15    599\n",
      "16      16    546\n",
      "17      17    564\n",
      "18      18    465\n",
      "19      19    377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('중복을 제외한 샘플의 수 : {}'.format(data['email'].nunique()))\n",
    "print('중복을 제외한 주제의 수 : {}'.format(data['target'].nunique()))\n",
    "print(data.groupby('target').size().reset_index(name='count'))\n",
    "data['target'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25e22419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\n",
      "Subject: Need info on 88-89 Bonneville\n",
      "Organization: University at Buffalo\n",
      "Lines: 10\n",
      "News-Software: VAX/VMS VNEWS 1.41\n",
      "Nntp-Posting-Host: ubvmsd.cc.buffalo.edu\n",
      "\n",
      "\n",
      " I am a little confused on all of the models of the 88-89 bonnevilles.\n",
      "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
      "differences are far as features or performance. I am also curious to\n",
      "know what the book value is for prefereably the 89 model. And how much\n",
      "less than book value can you usually get them for. In other words how\n",
      "much are they in demand this time of year. I have heard that the mid-spring\n",
      "early summer is the best time to buy.\n",
      "\n",
      "\t\t\tNeil Gandler\n",
      "\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임으로부터 다시 메일 본문과 레이블을 분리하고, 테스트 데이터 로딩\n",
    "newsdata_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "train_email = data['email']\n",
    "train_label = data['target']\n",
    "test_email = newsdata_test.data\n",
    "test_label = newsdata_test.target\n",
    "print(test_email[0]) # 첫번째 테스트 샘플\n",
    "print(test_label[0]) # 첫번째 테스트 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77d9a60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 본문의 크기 : (11314, 10000)\n",
      "훈련 샘플 레이블의 크기 : (11314, 20)\n",
      "테스트 샘플 본문의 크기 : (7532, 10000)\n",
      "테스트 샘플 레이블의 크기 : (7532, 20)\n",
      "빈도수 상위 1번 단어 : the\n",
      "빈도수 상위 9999번 단어 : mic\n"
     ]
    }
   ],
   "source": [
    "# 케라스의 토크나이저 도구를 사용하여 전처리를 진행\n",
    "\n",
    "vocab_size = 10000\n",
    "num_classes = 20\n",
    "\n",
    "def prepare_data(train_data, test_data, mode): # 전처리 함수\n",
    "    tokenizer = Tokenizer(num_words = vocab_size) # vocab_size 개수만큼의 단어만 사용\n",
    "    tokenizer.fit_on_texts(train_data)\n",
    "    X_train = tokenizer.texts_to_matrix(train_data, mode=mode) # 샘플 수 × vocab_size 크기의 행렬 생성\n",
    "    X_test = tokenizer.texts_to_matrix(test_data, mode=mode) # 샘플 수 × vocab_size 크기의 행렬 생성\n",
    "    return X_train, X_test, tokenizer.index_word\n",
    "\n",
    "# texts_to_matrix()를 사용하여 훈련 데이터와 테스트 데이터를 'binary' 모드로 변환\n",
    "X_train, X_test, index_to_word = prepare_data(train_email, test_email, 'binary') # binary 모드로 변환\n",
    "y_train = to_categorical(train_label, num_classes) # 원-핫 인코딩\n",
    "y_test = to_categorical(test_label, num_classes) # 원-핫 인코딩\n",
    "\n",
    "print('훈련 샘플 본문의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 본문의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))\n",
    "\n",
    "print('빈도수 상위 1번 단어 : {}'.format(index_to_word[1]))\n",
    "print('빈도수 상위 9999번 단어 : {}'.format(index_to_word[9999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d66ae56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "80/80 [==============================] - 3s 27ms/step - loss: 2.2816 - accuracy: 0.3412 - val_loss: 0.9453 - val_accuracy: 0.8260\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.8764 - accuracy: 0.7608 - val_loss: 0.4611 - val_accuracy: 0.8790\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4357 - accuracy: 0.8856 - val_loss: 0.3561 - val_accuracy: 0.8993\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2665 - accuracy: 0.9329 - val_loss: 0.3034 - val_accuracy: 0.9099\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.1736 - accuracy: 0.9589 - val_loss: 0.2883 - val_accuracy: 0.9108\n",
      "binary 모드의 테스트 정확도: 0.8285979628562927\n",
      "Epoch 1/5\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 2.8457 - accuracy: 0.2508 - val_loss: 1.6612 - val_accuracy: 0.7473\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 1.4761 - accuracy: 0.6224 - val_loss: 0.7014 - val_accuracy: 0.8551\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.8192 - accuracy: 0.7958 - val_loss: 0.5209 - val_accuracy: 0.8737\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.5224 - accuracy: 0.8678 - val_loss: 0.4234 - val_accuracy: 0.8852\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.4039 - accuracy: 0.9053 - val_loss: 0.4072 - val_accuracy: 0.8834\n",
      "count 모드의 테스트 정확도: 0.8141263723373413\n",
      "Epoch 1/5\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 2.2410 - accuracy: 0.3604 - val_loss: 0.7808 - val_accuracy: 0.8498\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.8305 - accuracy: 0.7758 - val_loss: 0.4323 - val_accuracy: 0.8869\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.4498 - accuracy: 0.8862 - val_loss: 0.3201 - val_accuracy: 0.9125\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.2770 - accuracy: 0.9278 - val_loss: 0.2882 - val_accuracy: 0.9170\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 0.2163 - accuracy: 0.9512 - val_loss: 0.2944 - val_accuracy: 0.9108\n",
      "tfidf 모드의 테스트 정확도: 0.8362984657287598\n",
      "Epoch 1/5\n",
      "80/80 [==============================] - 3s 25ms/step - loss: 2.9785 - accuracy: 0.0820 - val_loss: 2.9317 - val_accuracy: 0.1864\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 2.7428 - accuracy: 0.2003 - val_loss: 2.4113 - val_accuracy: 0.4647\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 2.1834 - accuracy: 0.3469 - val_loss: 1.8234 - val_accuracy: 0.6184\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 1.6839 - accuracy: 0.4914 - val_loss: 1.3840 - val_accuracy: 0.6837\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 1.3075 - accuracy: 0.6104 - val_loss: 1.0953 - val_accuracy: 0.7465\n",
      "freq 모드의 테스트 정확도: 0.6915825605392456\n"
     ]
    }
   ],
   "source": [
    "# 다층 퍼셉트론(Multilayer Perceptron, MLP)을 사용하여 텍스트 분류\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "def fit_and_evaluate(X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(vocab_size,), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=1, validation_split=0.1)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "    return score[1]\n",
    "\n",
    "modes = ['binary', 'count', 'tfidf', 'freq'] # 4개의 모드를 리스트에 저장\n",
    "\n",
    "for mode in modes: # 4개의 모드에 대해서 각각 아래의 작업을 반복\n",
    "    X_train, X_test, _ = prepare_data(train_email, test_email, mode) # 모드에 따라서 데이터를 전처리\n",
    "    score = fit_and_evaluate(X_train, y_train, X_test, y_test) # 모델을 훈련하고 평가\n",
    "    print(mode+' 모드의 테스트 정확도:', score)\n",
    "\n",
    "# 결과 분석 : \n",
    "# 대체적으로 82% ~ 83%의 비슷한 정확도가 나옴\n",
    "# 하지만 'freq' 모드에서만 정확도가 69%가 나옴\n",
    "# 'freq' 모드는 이번 분류에 적합한 전처리 방법이 아님"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

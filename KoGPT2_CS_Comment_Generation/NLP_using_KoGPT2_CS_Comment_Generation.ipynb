{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a753261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 12:57:49.051276: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-07 12:57:49.051331: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-07 12:57:54.733311: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-07 12:57:54.733355: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-07 12:57:54.733383: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-255-120-161): /proc/driver/nvidia/version does not exist\n",
      "2023-04-07 12:57:54.733720: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-07 12:57:54.765068: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.10.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'lm_head.weight', 'transformer.h.9.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.3.attn.masked_bias']\n",
      "- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the dataset @ CDT(2023-04-07T12:58:00.697277)\n",
      "Training the model @ CDT(2023-04-07T12:59:02.131955)\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbike/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377: FutureWarning: The old compute_loss method is deprecated as it conflicts with the Keras compute_loss method added in TF 2.8. If you want the original HF compute_loss, please call hf_compute_loss() instead. From TF versions >= 2.8, or Transformers versions >= 5, calling compute_loss() will get the Keras method instead.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 48s 868ms/step - loss: 7.9705\n",
      "Epoch 2/24\n",
      "24/24 [==============================] - 20s 840ms/step - loss: 2.9423\n",
      "Epoch 3/24\n",
      "24/24 [==============================] - 21s 861ms/step - loss: 0.5174\n",
      "Epoch 4/24\n",
      "24/24 [==============================] - 21s 876ms/step - loss: 0.1653\n",
      "Epoch 5/24\n",
      "24/24 [==============================] - 21s 862ms/step - loss: 0.0582\n",
      "Epoch 6/24\n",
      "24/24 [==============================] - 21s 872ms/step - loss: 0.0392\n",
      "Epoch 7/24\n",
      "24/24 [==============================] - 21s 879ms/step - loss: 0.0242\n",
      "Epoch 8/24\n",
      "24/24 [==============================] - 20s 835ms/step - loss: 0.0169\n",
      "Epoch 9/24\n",
      "24/24 [==============================] - 21s 853ms/step - loss: 0.0235\n",
      "Epoch 10/24\n",
      "24/24 [==============================] - 21s 874ms/step - loss: 0.0148\n",
      "Epoch 11/24\n",
      "24/24 [==============================] - 21s 882ms/step - loss: 0.0730\n",
      "Epoch 12/24\n",
      "24/24 [==============================] - 20s 844ms/step - loss: 0.0621\n",
      "Epoch 13/24\n",
      "24/24 [==============================] - 21s 885ms/step - loss: 0.0446\n",
      "Epoch 14/24\n",
      "24/24 [==============================] - 20s 856ms/step - loss: 0.0250\n",
      "Epoch 15/24\n",
      "24/24 [==============================] - 21s 859ms/step - loss: 0.0238\n",
      "Epoch 16/24\n",
      "24/24 [==============================] - 21s 873ms/step - loss: 0.0327\n",
      "Epoch 17/24\n",
      "24/24 [==============================] - 21s 869ms/step - loss: 0.0117\n",
      "Epoch 18/24\n",
      "24/24 [==============================] - 20s 844ms/step - loss: 0.0494\n",
      "Epoch 19/24\n",
      "24/24 [==============================] - 20s 833ms/step - loss: 0.0790\n",
      "Epoch 20/24\n",
      "24/24 [==============================] - 21s 856ms/step - loss: 0.0752\n",
      "Epoch 21/24\n",
      "24/24 [==============================] - 21s 855ms/step - loss: 0.0107\n",
      "Epoch 22/24\n",
      "24/24 [==============================] - 21s 871ms/step - loss: 0.0111\n",
      "Epoch 23/24\n",
      "24/24 [==============================] - 21s 866ms/step - loss: 0.0085\n",
      "Epoch 24/24\n",
      "24/24 [==============================] - 20s 841ms/step - loss: 0.1011\n",
      "Saving the model @ CDT(2023-04-07T13:09:27.783768)\n",
      " @ CDT(2023-04-07T13:09:29.864531)\n"
     ]
    }
   ],
   "source": [
    "# Print the current date and time in the format:\n",
    "# \"YYYY-MM-DD HH:MM:SS.microseconds\"\n",
    "import datetime\n",
    "def print_current_datetime(text=\"\"):\n",
    "    datetime_string = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    print(\"{} @ CDT({})\".format(text,datetime_string))\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, AutoTokenizer\n",
    "\n",
    "# Load the pre-trained GPT-2 model and tokenizer\n",
    "model = TFGPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2', from_pt=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2')\n",
    "\n",
    "# Set padding token\n",
    "tokenizer.add_special_tokens({'pad_token':'[PAD]'})\n",
    "\n",
    "print_current_datetime(\"Preparing the dataset\")\n",
    "\n",
    "'''\n",
    "Each training example consists of two sentences separated by a period (.) and a newline character (\\n).\n",
    "You can have as many training examples as you like in the \"train.txt\" file.\n",
    "An example of what the file might look like:\n",
    "\n",
    "This is the first sentence of the first training example. This is the second sentence of the first training example.\n",
    "This is the first sentence of the second training example. This is the second sentence of the second training example.\n",
    "'''\n",
    "\n",
    "# Load and preprocess the training data\n",
    "with open('dataset_for_cs_comment_two_sentences.txt', 'r') as f:\n",
    "    train_text = f.read()\n",
    "train_inputs = tokenizer(train_text, padding=True, truncation=True, max_length=280) # 데이터셋 타겟문장 최대 토큰 길이 (참고)\n",
    "\n",
    "print_current_datetime(\"Training the model\")\n",
    "\n",
    "# Fine-tune the model on the training data\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss)\n",
    "model.fit(train_inputs['input_ids'], train_inputs['input_ids'], batch_size=12, epochs=24)\n",
    "\n",
    "print_current_datetime(\"Saving the model\")\n",
    "\n",
    "# Save the finetuned model\n",
    "model.save_pretrained(\"output/finetuned-kogpt2-cs-comment-generation\")\n",
    "tokenizer.save_pretrained(\"output/finetuned-kogpt2-cs-comment-generation\")\n",
    "\n",
    "print_current_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb49c299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model @ CDT(2023-04-07T13:14:36.824846)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at output/finetuned-kogpt2-cs-comment-generation.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the output(1) @ CDT(2023-04-07T13:14:40.347334)\n",
      "Prompt: 엑셀이 작동을 안해요.\n",
      "Generated text 1 : 엑셀이 작동을 안해요. 엑엑 엑 엑시 엑사 엑스 엑소 엑텍 엑시스 엑다 엑오 엑스케 엑진 엑스피 엑질 엑에 엑나 엑비 엑일 엑트 엑스코 엑 엑스 엑피 엑트릭 엑트리 엑X 엑탈 엑니 엑시에 엑사르 엑 시 엑파시 엑시아 엑시, 엑시가 엑시를 엑시와 엑시( 엑시는 엑시의 엑스, 엑시오 엑시온 엑슨 엑스테 엑 이시 엑, 엑시로 엑사, 엑큐 엑스파 엑스가 엑스를 엑스나 엑스로 엑스에 엑트로 엑스( 엑스트라 엑시티 엑상 엑센터 엑스와 엑으 엑비아 엑스는 엑 중이 엑. 엑이나 엑이 엑사를 엑사나 엑사가 엑사로 엑사와 엑사인 엑케이 엑사( 엑사키 엑사이 엑사이드 엑스에서 엑사카 엑팔 엑아 엑프로 엑스레 엑고 엑페 엑발 엑환 엑거 엑산 엑원 엑폐 엑속 엑알 엑진, 엑진을 엑진과 엑진이 엑진으로 엑진에 엑으로 엑진( 엑진의 엑진은 엑지고 엑고, 엑도가 엑도를 엑지게 엑이고 엑져 엑도 엑돌 엑날 엑어서 엑지로 엑도로 엑데 엑더 엑아서 엑파 엑터 엑서 엑로 엑발로 엑도시 엑어 엑토 엑포 엑지 엑빌 엑가스 엑카 엑 다 엑\n",
      "Generating the output(2) @ CDT(2023-04-07T13:18:52.695899)\n",
      "Prompt: 엑셀이 작동을 안해요.\n",
      "Generated text: 엑스텍사 엑스, 중동 중이다오일환 환풍 및 해당된 시.시?중이다' 또는 '진중인 중인 있는 것으로 보이는되고 있으며, 진행될 예정돼 진행되고 가능하며, 가능한 가능 가능하다.\n",
      "가능하며, 불가능한 불가능되며, 가능하게 되며, 가능하도록 하며,가능한 할 수 없으며, 불가능하다.\n",
      "하지만, 불가하고, 수행할 가능성이 존재하며, 완료 될 경우, 진행할 대상이며, 수행할 대상으로 제공된다.\n",
      "단, 사용할 시, 필요한 모든 ( 혹은 그 중, 전 과정 중에 진행되는 결과, 현재 진행하는 즉시 실행되는 시스템으로 이루어지며, 플레이하고 이용할 대상이 필요하며, 동시에 실시할 경우 적용되며 서비스 운영 시스템을 통해 제공할 받을 필요하거나, 적용할 계획 진행된다.\n",
      "하여, 사용될 나갈 예정이다.\n",
      "해, 내 위치한 지정된 후, 바로 접근할 이용자가 참여할 대상을 지정했으며, 이를 위해 사용되며, 서비스를 제공하는 관련 개발 프로그램을 제공하고 지원하고자 하는 것이 된다.\n",
      "에서 사용되는 시스템은 적용될 가능성을 통해, 게임에 이용될 게임을 진행하고 있으며 또한 시행할 준비되어 있을 것이며, 또한, 발생할 가능성 보유(re-exion)을 위한 기술을 이용해 이루어질 예/또는 이에 적합한 기술 개발을 수행하고 있다.\n",
      " @ CDT(2023-04-07T13:20:42.904537)\n"
     ]
    }
   ],
   "source": [
    "# Print the current date and time in the format:\n",
    "# \"YYYY-MM-DD HH:MM:SS.microseconds\"\n",
    "import datetime\n",
    "def print_current_datetime(text=\"\"):\n",
    "    datetime_string = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    print(\"{} @ CDT({})\".format(text,datetime_string))\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, AutoTokenizer\n",
    "\n",
    "print_current_datetime(\"Loading the model\")\n",
    "\n",
    "# Load the fine-tuned GPT-2 model and tokenizer\n",
    "model = TFGPT2LMHeadModel.from_pretrained('output/finetuned-kogpt2-cs-comment-generation')\n",
    "tokenizer = AutoTokenizer.from_pretrained('output/finetuned-kogpt2-cs-comment-generation')\n",
    "\n",
    "print_current_datetime(\"Generating the output(1)\")\n",
    "\n",
    "# Generate text from the model\n",
    "prompt = '엑셀이 작동을 안해요.'\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='tf')\n",
    "output_ids = model.generate(input_ids=input_ids, max_length=280, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "generated_texts = [tokenizer.decode(output_id) for output_id in output_ids]\n",
    "\n",
    "print(\"Prompt: \" + prompt)\n",
    "for i, generated_text in enumerate(generated_texts):\n",
    "    print('Generated text', i+1, ':', generated_text)\n",
    "\n",
    "print_current_datetime(\"Generating the output(2)\")\n",
    "\n",
    "prompt = \"엑셀이 작동을 안해요.\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"tf\")\n",
    "output_ids = model.generate(input_ids=input_ids,\n",
    "                                   max_length=200+input_ids.shape[1],\n",
    "                                   num_beams=1, # Higher value increases the computational cost\n",
    "                                   no_repeat_ngram_size=1, # Higher means more repetitive words\n",
    "                                   repetition_penalty=2.0, # Higher avoids repeating sentences\n",
    "                                   temperature=0.1, # Higher means more diverse : 0 ~ 1\n",
    "                                   top_p=0.9, # Higher means more diverse : 0 ~ 1\n",
    "                                   early_stopping=True)\n",
    "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Prompt: \" + prompt)\n",
    "\n",
    "split_generated_text = generated_text.split(prompt)\n",
    "if len(split_generated_text) > 1:\n",
    "    generated_text = split_generated_text[1]\n",
    "# Trim the sentences after the last period(.)\n",
    "text_to_remove = generated_text.split('.')[-1]\n",
    "generated_text = generated_text.replace(text_to_remove,'')\n",
    "print(\"Generated text: \" + generated_text)\n",
    "\n",
    "print_current_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46847233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 16:30:58.056841: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-15 16:30:58.056870: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/gbike/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.7.0\n",
      "Transformers version: 4.21.0\n"
     ]
    }
   ],
   "source": [
    "# Execution Environment for KLUE-BERT\n",
    "# pip install tensorflow==2.7.0\n",
    "# pip install transformers==4.21.0\n",
    "# TensorFlow version: 2.7.0\n",
    "# Transformers version: 4.21.0\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "\n",
    "# Print the current date and time in the format:\n",
    "# \"YYYY-MM-DD HH:MM:SS.microseconds\"\n",
    "import datetime\n",
    "def print_current_datetime():\n",
    "    datetime_string = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    print(\"CDT(Current Date and Time):\", datetime_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8381beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 후 데이터셋 : 총 117,609개\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# Read Excel data\n",
    "df = pd.read_excel(\"[데이터셋] CS 신고관리 코멘트생성용 @ 전처리.xlsx\", sheet_name=\"전처리\")\n",
    "\n",
    "# Write CSV data\n",
    "df.to_csv(\"[데이터셋] CS 신고관리 코멘트생성용 @ 전처리.txt\", sep=\"\\t\", index=False)\n",
    "\n",
    "# 파일에서 \"\\t\" 을 \"|\" 변환 후 Prompt |[SEP]| Target Text [다음줄] 포맷으로 변경\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e01dd80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 16:31:01.948964: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-15 16:31:01.948990: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-15 16:31:01.949008: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-255-120-161): /proc/driver/nvidia/version does not exist\n",
      "2023-03-15 16:31:01.949221: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-15 16:31:01.962120: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.9.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'lm_head.weight', 'transformer.h.2.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.4.attn.masked_bias']\n",
      "- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 총 샘플 개수: 117609\n",
      "데이터셋 프롬프트 최대 토큰 길이: 137\n",
      "데이터셋 타겟문장 최대 토큰 길이: 278\n"
     ]
    }
   ],
   "source": [
    "# GPTv2 모델 사용\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, AutoTokenizer\n",
    "from timeit import default_timer\n",
    "\n",
    "# Load pre-trained GPT2 model and tokenizer\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\", from_pt=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")\n",
    "\n",
    "# Load the dataset of prompts and target texts\n",
    "# Prompt : a sentence, phrase, or a set of keywords that\n",
    "# act as a starting point for generating a response text\n",
    "with open(\"dataset_for_cs_comment_generation.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = [line.strip().split(\"|[SEP]|\") for line in f.readlines()]\n",
    "\n",
    "# Shuffle the dataset\n",
    "random.seed(1234)\n",
    "random.shuffle(dataset)\n",
    "\n",
    "print(\"데이터셋 총 샘플 개수:\", len(dataset))\n",
    "print(dataset[:2][:])\n",
    "\n",
    "sample_prompt = []\n",
    "sample_target = []\n",
    "for prompt, target in dataset:\n",
    "    sample_prompt.append(prompt)\n",
    "    sample_target.append(target)\n",
    "print(sample_prompt[:2])\n",
    "print(sample_target[:2])\n",
    "\n",
    "input_ids = []\n",
    "output_ids = []\n",
    "for prompt, target in dataset:\n",
    "    # Encode the prompt and target as input and output sequences\n",
    "    # Not using special tokens such as [CLS], [SEP], etc.\n",
    "    prompt_encoded = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "    target_encoded = tokenizer.encode(target, add_special_tokens=False)\n",
    "    # Add the encoded sequences to the input and output lists\n",
    "    input_ids.append(prompt_encoded)\n",
    "    output_ids.append(target_encoded)\n",
    "\n",
    "max_seq_length = 0\n",
    "for arr in input_ids:\n",
    "    if len(arr) > max_seq_length:\n",
    "        max_seq_length = len(arr)\n",
    "print(\"데이터셋 프롬프트 최대 토큰 길이:\", max_seq_length)\n",
    "max_seq_length = 0\n",
    "for arr in output_ids:\n",
    "    if len(arr) > max_seq_length:\n",
    "        max_seq_length = len(arr)\n",
    "print(\"데이터셋 타겟문장 최대 토큰 길이:\", max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b962e14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터셋 개수: 117609\n",
      "훈련 데이터셋 수: 105848\n",
      "검증 데이터셋 수: 11761\n",
      "Time duration(in seconds): 31.875500281108543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwith np.printoptions(threshold=np.inf):\\n    print(train_input_ids.shape)\\n    print(train_input_ids[:2])\\n    print(train_output_ids.shape)\\n    print(train_output_ids[:2])\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dataset to tokenized sequences\n",
    "input_ids = []\n",
    "output_ids = []\n",
    "\n",
    "start = default_timer()\n",
    "\n",
    "for prompt, target in dataset:\n",
    "    # Encode the prompt and target as input and output sequences\n",
    "    # Not using special tokens such as [CLS], [SEP], etc.\n",
    "    prompt_encoded = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "    target_encoded = tokenizer.encode(target, add_special_tokens=False)\n",
    "    input_seq = prompt_encoded\n",
    "    output_seq = target_encoded\n",
    "    # Truncate sequences that are too long\n",
    "    # For GPT2, the default value for max_seq_length is 1024\n",
    "    # Using the default value (1024) causes OOM error\n",
    "    # max_seq_length = model.config.n_positions\n",
    "    max_seq_length = 280 # 데이터셋 타겟문장 최대 토큰 길이 (참고)\n",
    "    if len(input_seq) > max_seq_length:\n",
    "        input_seq = input_seq[:max_seq_length]\n",
    "    if len(output_seq) > max_seq_length:\n",
    "        output_seq = output_seq[:max_seq_length]\n",
    "    # Pad sequences that are too short\n",
    "    # The default value for padding in GPT2 tokenizer is 0\n",
    "    # Using tokenizer.pad_token_id value (None) causes error\n",
    "    # because None str is not int64 type, which is required\n",
    "    padding_length_input_seq = max_seq_length - len(input_seq)\n",
    "    if ( padding_length_input_seq > 0 ):\n",
    "        input_seq += [0] * padding_length_input_seq\n",
    "    padding_length_output_seq = max_seq_length - len(output_seq)\n",
    "    if ( padding_length_output_seq > 0 ):\n",
    "        output_seq += [0] * padding_length_output_seq\n",
    "    '''\n",
    "    padding_length_input_seq = max_seq_length - len(input_seq)\n",
    "    if ( padding_length_input_seq > 0 ):\n",
    "        input_seq += [tokenizer.pad_token_id] * padding_length_input_seq\n",
    "    padding_length_output_seq = max_seq_length - len(output_seq)\n",
    "    if ( padding_length_output_seq > 0 ):\n",
    "        output_seq += [tokenizer.pad_token_id] * padding_length_output_seq\n",
    "    '''\n",
    "    # Add the encoded sequences to the input and output lists\n",
    "    input_ids.append(input_seq)\n",
    "    output_ids.append(output_seq)\n",
    "\n",
    "# Convert inputs and outputs to numpy arrays\n",
    "# also change the type from object to int64\n",
    "input_ids = np.array(input_ids).astype('int64') # Vectorized prompts\n",
    "output_ids = np.array(output_ids).astype('int64') # Vectorized target texts\n",
    "\n",
    "# Split data into training and validation sets\n",
    "split_length = int(len(input_ids) * 0.9)\n",
    "train_input_ids = input_ids[:split_length]\n",
    "train_output_ids = output_ids[:split_length]\n",
    "val_input_ids = input_ids[split_length:]\n",
    "val_output_ids = output_ids[split_length:]\n",
    "print(\"총 데이터셋 개수:\", len(input_ids))\n",
    "print(\"훈련 데이터셋 수:\", split_length)\n",
    "print(\"검증 데이터셋 수:\", len(input_ids) - split_length)\n",
    "\n",
    "end = default_timer()\n",
    "print(\"Time duration(in seconds):\", end - start)\n",
    "\n",
    "# Temporary setting to print full numpy array\n",
    "'''\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    print(train_input_ids.shape)\n",
    "    print(train_input_ids[:2])\n",
    "    print(train_output_ids.shape)\n",
    "    print(train_output_ids[:2])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613ebaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDT(Current Date and Time): 2023-03-15 14:24:58.601592\n",
      "[모델 학습 시간]\n",
      "Epoch 1/10\n",
      "26462/26462 [==============================] - 82915s 3s/step - loss: 0.5108 - val_loss: 0.4871\n",
      "Epoch 2/10\n",
      "26462/26462 [==============================] - 82853s 3s/step - loss: 0.4833 - val_loss: 0.4782\n",
      "Epoch 3/10\n",
      "26462/26462 [==============================] - 83607s 3s/step - loss: 0.4746 - val_loss: 0.4762\n",
      "Epoch 4/10\n",
      "26462/26462 [==============================] - 83121s 3s/step - loss: 0.4675 - val_loss: 0.4774\n",
      "Epoch 5/10\n",
      "26462/26462 [==============================] - 83124s 3s/step - loss: 0.4606 - val_loss: 0.4839\n",
      "Epoch 00005: early stopping\n",
      "Time duration(in seconds): 415620.239709207\n",
      "CDT(Current Date and Time): 2023-03-20 09:51:58.842216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('output/finetuned-kogpt2-cs-comment-generation/tokenizer_config.json',\n",
       " 'output/finetuned-kogpt2-cs-comment-generation/special_tokens_map.json',\n",
       " 'output/finetuned-kogpt2-cs-comment-generation/vocab.json',\n",
       " 'output/finetuned-kogpt2-cs-comment-generation/merges.txt',\n",
       " 'output/finetuned-kogpt2-cs-comment-generation/added_tokens.json',\n",
       " 'output/finetuned-kogpt2-cs-comment-generation/tokenizer.json')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print_current_datetime()\n",
    "\n",
    "print(\"[모델 학습 시간]\")\n",
    "start = default_timer()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss)\n",
    "\n",
    "# 모델 학습 시 성능이 개선되지 않는 횟수가 2회를 초과하면 학습을 멈춤\n",
    "earlystop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(train_input_ids, train_output_ids,\n",
    "          validation_data=(val_input_ids,val_output_ids),\n",
    "          callbacks=[earlystop],\n",
    "          batch_size = 4, # 약 12GB 메모리사용\n",
    "          epochs = 10)\n",
    "\n",
    "end = default_timer()\n",
    "print(\"Time duration(in seconds):\", end - start)\n",
    "\n",
    "print_current_datetime()\n",
    "\n",
    "# 모델 저장\n",
    "\n",
    "model.save_pretrained(\"output/finetuned-kogpt2-cs-comment-generation\")\n",
    "tokenizer.save_pretrained(\"output/finetuned-kogpt2-cs-comment-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc1caf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1cfa721790>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation val_loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c42e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델 로드 및 테스트\n",
    "from transformers import TFGPT2LMHeadModel, AutoTokenizer\n",
    "from timeit import default_timer\n",
    "\n",
    "print(\"[모델 로딩 시간]\")\n",
    "start = default_timer()\n",
    "\n",
    "loaded_model = TFGPT2LMHeadModel.from_pretrained(\"output/finetuned-kogpt2-cs-comment-generation-epoch1\")\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(\"output/finetuned-kogpt2-cs-comment-generation-epoch1\")\n",
    "\n",
    "end = default_timer()\n",
    "print(\"Time duration(in seconds):\", end - start)\n",
    "\n",
    "print(\"[문장 생성 시간]\")\n",
    "start = default_timer()\n",
    "\n",
    "prompt = \"환불 요청 안함 | 탑승 전 | 엑셀,바퀴 | 엑셀이 작동을 안해요\"\n",
    "input_ids = loaded_tokenizer.encode(prompt, return_tensors=\"tf\")\n",
    "output_ids = loaded_model.generate(input_ids=input_ids,\n",
    "                                   max_length=200+input_ids.shape[1],\n",
    "                                   num_beams=1, # Higher value increases the computational cost\n",
    "                                   no_repeat_ngram_size=1, # Higher means more repetitive words\n",
    "                                   repetition_penalty=2.0, # Higher avoids repeating sentences\n",
    "                                   temperature=0.1, # Higher means more diverse : 0 ~ 1\n",
    "                                   top_p=0.9, # Higher means more diverse : 0 ~ 1\n",
    "                                   early_stopping=True)\n",
    "generated_text = loaded_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Prompt: \" + prompt)\n",
    "\n",
    "split_generated_text = generated_text.split(prompt)\n",
    "if len(split_generated_text) > 1:\n",
    "    generated_text = split_generated_text[1]\n",
    "# Trim the sentences after the last period(.)\n",
    "text_to_remove = generated_text.split('.')[-1]\n",
    "generated_text = generated_text.replace(text_to_remove,'')\n",
    "print(\"Generated text: \" + generated_text)\n",
    "\n",
    "end = default_timer()\n",
    "print(\"Time duration(in seconds):\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c7689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDT(Current Date and Time): 2023-03-15 16:32:10.822238\n",
      "[모델 학습 시간]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbike/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377: FutureWarning: The old compute_loss method is deprecated as it conflicts with the Keras compute_loss method added in TF 2.8. If you want the original HF compute_loss, please call hf_compute_loss() instead. From TF versions >= 2.8, or Transformers versions >= 5, calling compute_loss() will get the Keras method instead.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26462/26462 [==============================] - 86261s 3s/step - loss: 0.5165 - val_loss: 0.4861\n",
      "Time duration(in seconds): 86261.62590811285\n",
      "CDT(Current Date and Time): 2023-03-16 16:29:52.448478\n",
      "[문장 생성 시간]\n",
      "Prompt: 환불 요청 안함 | 탑승 전 | 엑셀,바퀴 | 엑셀이 작동을 안해요\n",
      "Generated text: 환불 요청 안함 | 탑승 전 | 엑셀,바퀴 | 엑셀이 작동을 안해요 수거/점검 진행하도록 하겠습니다. 감사합니다. 또한,기는팀 점검하였습니다. 확인하여 이용에드 않도록하겠 감사 접수 꼼꼼히 확인 진행할 있도록습니다. 더욱 하겠 빠른릴 수 노력 운영립니다.합니다.습니다.합니다.합니다. 감사 감사 하겠 감사 수합니다. 노력 감사하겠 감사습니다.습니다.으로 불편 기 드 서비스 해당하여으로습니다. 접수합니다. 꼼꼼히리지시 부탁드리해 보려 반납겠며, 후 점 불편을 종료실 죄하다는 고객송 다시 번 환 양 답 이용어진될 신고금셔 도와하 미니 시 늦변일 경우구역 가능지면 참고 영업되 주차 기기 카드다 소요신 결제 확인 감사팀습니다. 확인 확인습니다. 수습니다.팀 감사 접수 접수 감사드습니다.드 감사 확인으로합니다. 수 감사 점검 감사 꼼꼼히 감사으로 감사하여 감사 운영 감사 노력합니다.팀팀합니다.으로 확인합니다. 확인\n",
      "Time duration(in seconds): 107.95419706590474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('output/finetuned-kogpt2-cs-comment-generation-epoch1/tokenizer_config.json',\n",
       " 'output/finetuned-kogpt2-cs-comment-generation-epoch1/special_tokens_map.json',\n",
       " 'output/finetuned-kogpt2-cs-comment-generation-epoch1/vocab.json',\n",
       " 'output/finetuned-kogpt2-cs-comment-generation-epoch1/merges.txt',\n",
       " 'output/finetuned-kogpt2-cs-comment-generation-epoch1/added_tokens.json',\n",
       " 'output/finetuned-kogpt2-cs-comment-generation-epoch1/tokenizer.json')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 에폭 한번 학습당 약 24시간(하루) 걸림 @ No GPU\n",
    "# Normal fine-tuning steps are around 10000s\n",
    "# and the number of epochs are around 10s\n",
    "print_current_datetime()\n",
    "\n",
    "print(\"[모델 학습 시간]\")\n",
    "start = default_timer()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss)\n",
    "\n",
    "history = model.fit(train_input_ids, train_output_ids,\n",
    "          validation_data=(val_input_ids,val_output_ids),\n",
    "          batch_size = 4, # 약 12GB 메모리사용\n",
    "          epochs = 1)\n",
    "\n",
    "end = default_timer()\n",
    "print(\"Time duration(in seconds):\", end - start)\n",
    "\n",
    "print_current_datetime()\n",
    "\n",
    "print(\"[문장 생성 시간]\")\n",
    "start = default_timer()\n",
    "\n",
    "# Generate text from prompt :\n",
    "# In text generation tasks, a 2-gram refers to a sequence of two consecutive words\n",
    "# and early_stopping parameter specifies whether to stop generation as soon as\n",
    "# all beam hypotheses (num_beams=5) have generated an end-of-sequence token\n",
    "prompt = \"환불 요청 안함 | 탑승 전 | 엑셀,바퀴 | 엑셀이 작동을 안해요\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"tf\")\n",
    "output_ids = model.generate(input_ids=input_ids, max_length=280, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Prompt: \" + prompt)\n",
    "print(\"Generated text: \" + generated_text)\n",
    "\n",
    "end = default_timer()\n",
    "print(\"Time duration(in seconds):\", end - start)\n",
    "\n",
    "# 모델 저장\n",
    "\n",
    "model.save_pretrained(\"output/finetuned-kogpt2-cs-comment-generation-epoch1\")\n",
    "tokenizer.save_pretrained(\"output/finetuned-kogpt2-cs-comment-generation-epoch1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

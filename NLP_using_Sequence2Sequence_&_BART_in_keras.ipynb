{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d143dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "np.random.seed(seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd160c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 리뷰 개수 : 30000\n"
     ]
    }
   ],
   "source": [
    "# AWS_Food_Reviews.csv 데이터를 데이터프레임에 저장 (3만개의 행(rows)만 추출)\n",
    "data = pd.read_csv(\"AWS_Food_Reviews.csv\", nrows = 30000)\n",
    "print('전체 리뷰 개수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c02e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...  \n",
      "                                                Text                Summary\n",
      "0  I have bought several of the Vitality canned d...  Good Quality Dog Food\n",
      "1  Product arrived labeled as Jumbo Salted Peanut...      Not as Advertised\n",
      "2  This is a confection that has been around a fe...  \"Delight\" says it all\n",
      "3  If you are looking for the secret ingredient i...         Cough Medicine\n",
      "4  Great taffy at a great price.  There was a wid...            Great taffy\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "data = data[['Text','Summary']]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43fbd935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 28677\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 24651\n",
      "Text       0\n",
      "Summary    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Summary는 중복이 더 많지만, 원문은 다르더라도 짧은 문장인 요약은 내용이 겹칠 수 있음을 가정\n",
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3117f5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 28677\n"
     ]
    }
   ],
   "source": [
    "# text 열에서 중복인 내용이 있다면 중복 제거\n",
    "data.drop_duplicates(subset=['Text'], inplace=True)\n",
    "print(\"전체 샘플수 :\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed4579d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "{'very', \"you'd\", 'nor', 't', \"couldn't\", 'both', 'me', \"isn't\", 'again', 'yourself', \"mightn't\", 'our', 'your', \"that'll\", 'because', \"should've\", 've', 'before', 'once', 'each', 'mustn', 'more', 'don', 'was', 'to', 'those', 'an', 'how', 'than', \"mustn't\", 'weren', 'below', \"you're\", 'whom', 'then', 'needn', 'not', 'with', 'out', 'were', 'can', 'you', 'being', 'ourselves', 'other', 'into', \"she's\", 'why', 'hadn', 'y', 'his', \"you'll\", 'no', 'theirs', \"hasn't\", 'has', 'doesn', 'didn', \"doesn't\", 'about', 'further', 'between', \"don't\", 'o', 'from', \"needn't\", 'ain', \"hadn't\", 'this', 'in', 'him', 'am', 'itself', \"weren't\", 'its', 'wasn', 'will', \"aren't\", 'most', 're', 'few', 'if', 'now', 'by', 'yours', 'ours', 'any', 'which', 'all', 'couldn', \"wasn't\", 'until', 'doing', 'after', 'have', 'where', 'm', 'a', 'myself', 'for', 'do', 'ma', 'the', 'so', \"haven't\", 'herself', 'is', 'hasn', 'shouldn', 'as', \"won't\", 'yourselves', \"shouldn't\", 'too', \"didn't\", 'he', 'won', 'haven', 'does', 'been', 'under', 'down', 'having', 'mightn', 'what', 'are', 'over', 'wouldn', 'of', 'she', 'own', 'll', \"it's\", 'same', 'against', 'only', 'here', 'there', 'during', 'they', 'my', 'be', 'had', 'himself', 'their', \"you've\", 'did', \"shan't\", 'or', 'her', 'through', 'some', 'just', 'that', 'we', 'it', 'i', 'who', 'isn', 'themselves', 'and', 'd', 'but', 'them', 'shan', 'aren', 'these', 'at', 'on', \"wouldn't\", 'such', 'off', 'up', 'when', 'above', 'should', 'while', 's', 'hers'}\n"
     ]
    }
   ],
   "source": [
    "# 단어(약어) 정규화 및 불용어 제거 :\n",
    "# 동일한 의미를 가졌지만 스펠링이 다른 단어들을 정규화하기 위한 사전\n",
    "# https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions = {\n",
    "\"'cause\": 'because',\n",
    " \"I'd\": 'I would',\n",
    " \"I'd've\": 'I would have',\n",
    " \"I'll\": 'I will',\n",
    " \"I'll've\": 'I will have',\n",
    " \"I'm\": 'I am',\n",
    " \"I've\": 'I have',\n",
    " \"ain't\": 'is not',\n",
    " \"aren't\": 'are not',\n",
    " \"can't\": 'cannot',\n",
    " \"could've\": 'could have',\n",
    " \"couldn't\": 'could not',\n",
    " \"didn't\": 'did not',\n",
    " \"doesn't\": 'does not',\n",
    " \"don't\": 'do not',\n",
    " \"hadn't\": 'had not',\n",
    " \"hasn't\": 'has not',\n",
    " \"haven't\": 'have not',\n",
    " \"he'd\": 'he would',\n",
    " \"he'll\": 'he will',\n",
    " \"he's\": 'he is',\n",
    " \"here's\": 'here is',\n",
    " \"how'd\": 'how did',\n",
    " \"how'd'y\": 'how do you',\n",
    " \"how'll\": 'how will',\n",
    " \"how's\": 'how is',\n",
    " \"i'd\": 'i would',\n",
    " \"i'd've\": 'i would have',\n",
    " \"i'll\": 'i will',\n",
    " \"i'll've\": 'i will have',\n",
    " \"i'm\": 'i am',\n",
    " \"i've\": 'i have',\n",
    " \"isn't\": 'is not',\n",
    " \"it'd\": 'it would',\n",
    " \"it'd've\": 'it would have',\n",
    " \"it'll\": 'it will',\n",
    " \"it'll've\": 'it will have',\n",
    " \"it's\": 'it is',\n",
    " \"let's\": 'let us',\n",
    " \"ma'am\": 'madam',\n",
    " \"mayn't\": 'may not',\n",
    " \"might've\": 'might have',\n",
    " \"mightn't\": 'might not',\n",
    " \"mightn't've\": 'might not have',\n",
    " \"must've\": 'must have',\n",
    " \"mustn't\": 'must not',\n",
    " \"mustn't've\": 'must not have',\n",
    " \"needn't\": 'need not',\n",
    " \"needn't've\": 'need not have',\n",
    " \"o'clock\": 'of the clock',\n",
    " \"oughtn't\": 'ought not',\n",
    " \"oughtn't've\": 'ought not have',\n",
    " \"sha'n't\": 'shall not',\n",
    " \"shan't\": 'shall not',\n",
    " \"shan't've\": 'shall not have',\n",
    " \"she'd\": 'she would',\n",
    " \"she'd've\": 'she would have',\n",
    " \"she'll\": 'she will',\n",
    " \"she'll've\": 'she will have',\n",
    " \"she's\": 'she is',\n",
    " \"should've\": 'should have',\n",
    " \"shouldn't\": 'should not',\n",
    " \"shouldn't've\": 'should not have',\n",
    " \"so's\": 'so as',\n",
    " \"so've\": 'so have',\n",
    " \"that'd\": 'that would',\n",
    " \"that'd've\": 'that would have',\n",
    " \"that's\": 'that is',\n",
    " \"there'd\": 'there would',\n",
    " \"there'd've\": 'there would have',\n",
    " \"there's\": 'there is',\n",
    " \"they'd\": 'they would',\n",
    " \"they'd've\": 'they would have',\n",
    " \"they'll\": 'they will',\n",
    " \"they'll've\": 'they will have',\n",
    " \"they're\": 'they are',\n",
    " \"they've\": 'they have',\n",
    " \"this's\": 'this is',\n",
    " \"to've\": 'to have',\n",
    " \"wasn't\": 'was not',\n",
    " \"we'd\": 'we would',\n",
    " \"we'd've\": 'we would have',\n",
    " \"we'll\": 'we will',\n",
    " \"we'll've\": 'we will have',\n",
    " \"we're\": 'we are',\n",
    " \"we've\": 'we have',\n",
    " \"weren't\": 'were not',\n",
    " \"what'll\": 'what will',\n",
    " \"what'll've\": 'what will have',\n",
    " \"what're\": 'what are',\n",
    " \"what's\": 'what is',\n",
    " \"what've\": 'what have',\n",
    " \"when's\": 'when is',\n",
    " \"when've\": 'when have',\n",
    " \"where'd\": 'where did',\n",
    " \"where's\": 'where is',\n",
    " \"where've\": 'where have',\n",
    " \"who'll\": 'who will',\n",
    " \"who'll've\": 'who will have',\n",
    " \"who's\": 'who is',\n",
    " \"who've\": 'who have',\n",
    " \"why's\": 'why is',\n",
    " \"why've\": 'why have',\n",
    " \"will've\": 'will have',\n",
    " \"won't\": 'will not',\n",
    " \"won't've\": 'will not have',\n",
    " \"would've\": 'would have',\n",
    " \"wouldn't\": 'would not',\n",
    " \"wouldn't've\": 'would not have',\n",
    " \"y'all\": 'you all',\n",
    " \"y'all'd\": 'you all would',\n",
    " \"y'all'd've\": 'you all would have',\n",
    " \"y'all're\": 'you all are',\n",
    " \"y'all've\": 'you all have',\n",
    " \"you'd\": 'you would',\n",
    " \"you'd've\": 'you would have',\n",
    " \"you'll\": 'you will',\n",
    " \"you'll've\": 'you will have',\n",
    " \"you're\": 'you are',\n",
    " \"you've\": 'you have'\n",
    "}\n",
    "\n",
    "# NLTK 모듈 내 불용어\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print('불용어 개수 :', len(stop_words))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab55719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "import re # Regular expression operation module\n",
    "def preprocess_sentence(sentence, remove_stopwords = True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열  제거, eg. my husband (and myself) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 단어(약어) 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거, eg. roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경, eg. ummmmmmm yeah -> umm yeah\n",
    "\n",
    "    if remove_stopwords: # 불용어 제거 (Text)\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stop_words if len(word) > 1)\n",
    "    else: # 불용어 미제거 (Summary), ie. remove_stopwords = False\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba8a063",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# 전처리 테스트\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a3a3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better', 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo', 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch', 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal', 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']\n",
      "['good quality dog food', 'not as advertised', 'delight says it all', 'cough medicine', 'great taffy']\n",
      "Text        0\n",
      "Summary    25\n",
      "dtype: int64\n",
      "전체 샘플수 : 28652\n"
     ]
    }
   ],
   "source": [
    "# Text 열 전처리\n",
    "clean_text = []\n",
    "for s in data['Text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "print(clean_text[:5])\n",
    "\n",
    "# Summary 열 전처리\n",
    "clean_summary = []\n",
    "for s in data['Summary']:\n",
    "    clean_summary.append(preprocess_sentence(s, False))\n",
    "print(clean_summary[:5])\n",
    "\n",
    "# 전처리 후의 결과를 다시 데이터프레임에 저장\n",
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 길이가 공백인 샘플은 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Null 값을 가지는 샘플 제거\n",
    "data.dropna(axis = 0, inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360eb2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 4\n",
      "텍스트의 최대 길이 : 863\n",
      "텍스트의 평균 길이 : 37.92873097864023\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 25\n",
      "요약의 평균 길이 : 3.983770766438643\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcqklEQVR4nO3df7wddX3n8deb8ENUIkQCGxMwYLMqoPIjIF3RoqwSi1vwsYLBVVCx2SIKtqgN1VbsNtu4tixiFzSIJChIs1UkFVFiFopoBG4gJQlIiRAhkiUREAJoNOHdP+YbPdzce2eS3HPuyT3v5+MxjzPnc2bmfCbnkXzy/X5nviPbREREDGWnkU4gIiK6X4pFRETUSrGIiIhaKRYREVErxSIiImqlWERERK0Ui4iIqJViEQFIOkbSDyU9IekxST+QdORI5xXRLXYe6QQiRpqkscC3gDOB+cCuwOuBDSOZ19aQJEC2nx3pXGJ0SssiAv4jgO2v2d5k+5e2b7B9l6TzJX1184aSJkuypJ3L+5sk/U1plTwl6Z8lvVjSlZKelHS7pMkt+1vSByXdJ2m9pP8h6WWSFpft50vatWy7l6RvSVon6fGyPqnlWDdJmiXpB8AzwLmSlrSemKRzJX2znX940RtSLCLg34BNkuZJequkvbZy/+nAe4CJwMuAxcDlwDjgHuBT/bafBhwBHA18HJgD/DdgP+AQ4NSy3U7lOC8F9gd+CfxDv2O9B5gB7AFcBBwg6ZUtn78b+MpWnk/EFlIsoufZfhI4BjBwKbBO0gJJ+zY8xOW2f2L7CeB64Ce2v2d7I/B/gcP6bf8Z20/aXgEsB26wfX/L/oeVvB61/XXbz9heD8wC/qDfsebaXmF7o+0NwD9SFQgkHQxMpupii9guKRYRgO17bL/X9iSq/92/BLiw4e6PtKz/coD3L9yW7SU9X9IXJf1U0pPAzcCeksa0bP9Qv2PPA95VxjDeA8wvRSRiu6RYRPRj+8fAXKqi8TTw/JaP/0MHUzkXeDnwWttjgTeUuFq2ec600bZ/BPyaaoD+XaQLKoZJikX0PEmvKAPBk8r7/ajGDX4ELAXeIGl/SS8CzutgantQtTR+IWkcW459DOYKqrGNjbZvaVdy0VtSLCJgPfBa4FZJT1MVieXAubYXUo0D3AUsobP9/xcCuwM/Lzl9p+F+X6FqFaVVEcNGefhRxOgiaXdgLXC47ftGOp8YHdKyiBh9zgRuT6GI4ZQ7uCNGEUmrqAbATxrZTGK0STdURETUSjdURETUGrXdUHvvvbcnT5480mlEROxQlixZ8nPb4/vHR22xmDx5Mn19fSOdRkTEDkXSTweKpxsqIiJqpVhEREStFIuIiKiVYhEREbVSLCIiolaKRURE1EqxiIiIWikWERFRK8UiIiJqjdo7uNtp8szrBv1s1ewTOphJRERnpGURERG1UiwiIqJWikVERNRKsYiIiFopFhERUautxULSnpL+SdKPJd0j6fcljZO0UNJ95XWvlu3Pk7RS0r2Sjm+JHyFpWfnsIklqZ94REfFc7W5ZfA74ju1XAK8B7gFmAotsTwEWlfdIOgiYDhwMTAMuljSmHOcSYAYwpSzT2px3RES0aFuxkDQWeANwGYDtX9v+BXAiMK9sNg84qayfCFxte4PtB4CVwFGSJgBjbS+2beCKln0iIqID2tmyOBBYB1wu6U5JX5L0AmBf22sAyus+ZfuJwEMt+68usYllvX98C5JmSOqT1Ldu3brhPZuIiB7WzmKxM3A4cIntw4CnKV1OgxhoHMJDxLcM2nNsT7U9dfz4LZ43HhER26idxWI1sNr2reX9P1EVj0dK1xLldW3L9vu17D8JeLjEJw0Qj4iIDmlbsbD9/4GHJL28hI4D7gYWAKeX2OnAtWV9ATBd0m6SDqAayL6tdFWtl3R0uQrqtJZ9IiKiA9o9keCHgSsl7QrcD7yPqkDNl3QG8CBwMoDtFZLmUxWUjcBZtjeV45wJzAV2B64vS0REdEhbi4XtpcDUAT46bpDtZwGzBoj3AYcMa3IREdFY7uCOiIhaKRYREVErxSIiImqlWERERK0Ui4iIqJViERERtVIsIiKiVopFRETUSrGIiIhaKRYREVErxSIiImqlWERERK0Ui4iIqNXuKcqjn8kzrxv0s1WzT+hgJhERzaVlERERtVIsIiKiVopFRETUSrGIiIhaKRYREVErxSIiImqlWERERK0Ui4iIqJViERERtVIsIiKiVluLhaRVkpZJWiqpr8TGSVoo6b7yulfL9udJWinpXknHt8SPKMdZKekiSWpn3hER8VydaFm80fahtqeW9zOBRbanAIvKeyQdBEwHDgamARdLGlP2uQSYAUwpy7QO5B0REcVIdEOdCMwr6/OAk1riV9veYPsBYCVwlKQJwFjbi20buKJln4iI6IB2FwsDN0haImlGie1rew1Aed2nxCcCD7Xsu7rEJpb1/vEtSJohqU9S37p164bxNCIielu7pyh/ne2HJe0DLJT04yG2HWgcwkPEtwzac4A5AFOnTh1wm4iI2HptbVnYfri8rgWuAY4CHildS5TXtWXz1cB+LbtPAh4u8UkDxCMiokPaViwkvUDSHpvXgbcAy4EFwOlls9OBa8v6AmC6pN0kHUA1kH1b6apaL+nochXUaS37REREB7SzG2pf4JpylevOwFW2vyPpdmC+pDOAB4GTAWyvkDQfuBvYCJxle1M51pnAXGB34PqyREREh7StWNi+H3jNAPFHgeMG2WcWMGuAeB9wyHDnGBERzeQO7oiIqJViERERtVIsIiKiVopFRETUqi0Wkk5uuQT2k5K+Ienw9qcWERHdoknL4i9tr5d0DHA81XxOl7Q3rYiI6CZNisXmex1OAC6xfS2wa/tSioiIbtOkWPxM0heBU4BvS9qt4X4RETFKNPlH/xTgu8A0278AxgEfa2dSERHRXWqLhe1nqCb7O6aENgL3tTOpiIjoLrXTfUj6FDAVeDlwObAL8FXgde1NLfqbPPO6IT9fNfuEDmUSEb2mSTfU24E/Ap6G3047vkc7k4qIiO7SpFj8ujzO1PDb6cYjIqKHNCkW88vVUHtK+mPge8Cl7U0rIiK6Se2Yhe2/k/Rm4EmqcYu/sr2w7ZlFRETXaPQ8i1IcUiAiInrUoMVC0nrKOEX/jwDbHtu2rCIioqsMWixs54qniIgAGnZDlVlmj6Fqadxi+862ZhUREV2lyRTlf0U10+yLgb2BuZI+2e7EIiKiezRpWZwKHGb7VwCSZgN3AH/TzsQiIqJ7NLnPYhXwvJb3uwE/aUs2ERHRlZq0LDYAKyQtpBqzeDNwi6SLAGyf3cb8IiKiCzQpFteUZbOb2pNKRER0qyZ3cM/bni+QNAboA35m+22SxgH/CEym6uI6xfbjZdvzgDOons53tu3vlvgRwFxgd+DbwDllvqqIiOiAJldDvU3SnZIek/SkpPWSntyK7zgHuKfl/Uxgke0pwKLyHkkHAdOBg4FpwMWl0ED1zO8ZwJSyTNuK74+IiO3UZID7QuB04MW2x9reo+nd25ImUT27+0st4ROpLsWlvJ7UEr/a9gbbDwArgaMkTQDG2l5cWhNXtOwTEREd0KRYPAQs38ZunwuBjwPPtsT2tb0GoLzuU+ITy3dttrrEJpb1/vEtSJohqU9S37p167Yh3YiIGEiTAe6PA9+W9C9UV0YBYPuCoXaS9DZgre0lko5t8D0aIOYh4lsG7TnAHICpU6dmTCMiYpg0KRazgKeo7rXYdSuO/TrgjyT9Ydl3rKSvAo9ImmB7TeliWlu2Xw3s17L/JODhEp80QDwiIjqkSbEYZ/stW3tg2+cB5wGUlsVHbb9b0mepxkBml9dryy4LgKskXQC8hGog+zbbm8qg+tHArcBpwOe3Np+IiNh2TcYsvidpq4vFEGYDb5Z0H9UNfrMBbK8A5gN3A98BzrK9qexzJtUg+Uqqu8evH8Z8IiKiRpOWxVnAxyVtAH7DNjzPwvZNlJv5bD8KHDfIdrOour36x/uAQ5p+X0REDK8mN+XluRYRET2u6fMs9qIaQ/jthIK2b25XUhER0V1qi4WkD1DdhT0JWAocDSwG3tTWzCIioms0GeA+BzgS+KntNwKHAbnjLSKihzQpFr9qefDRbrZ/DLy8vWlFREQ3aTJmsVrSnsA3gYWSHic3xUVE9JQmV0O9vayeL+lG4EVU90FERESPaDJF+csk7bb5LdVzKJ7fzqQiIqK7NBmz+DqwSdLvAZcBBwBXtTWriIjoKk2KxbO2NwJvBy60/afAhPamFRER3aRJsfiNpFOpJv37Vont0r6UIiKi2zQpFu8Dfh+YZfsBSQcAX21vWhER0U2aXA11N3B2y/sHKDPFRkREb2jSsoiIiB6XYhEREbUGLRaSvlJez+lcOhER0Y2GGrM4QtJLgfdLuoLqhrzfsv1YWzOLrTZ55nWDfrZq9gkdzCQiRpuhisUXqKb1OBBYwnOLhUs8IiJ6wKDdULYvsv1K4Mu2D7R9QMuSQhER0UOaXDp7pqTXAK8voZtt39XetCIiops0mUjwbOBKYJ+yXCnpw+1OLCIiukeT51l8AHit7acBJH2G6rGqn29nYhER0T2a3GchYFPL+030uzIqIiJGtyYti8uBWyVdU96fRDVVeURE9IjaloXtC6gmE3wMeBx4n+0L6/aT9DxJt0n6V0krJH26xMdJWijpvvK6V8s+50laKeleSce3xI+QtKx8dpGktGwiIjqo0XQftu8ol9J+zvadDY+9AXiT7dcAhwLTJB0NzAQW2Z4CLCrvkXQQMB04GJgGXCxpTDnWJcAMYEpZpjXMISIihkHb5oZy5anydpeyGDgRmFfi86i6tSjxq21vKDPbrgSOkjQBGGt7sW0DV7TsExERHdDWiQQljZG0FFgLLLR9K7Cv7TUA5XWfsvlE4KGW3VeX2MSy3j8+0PfNkNQnqW/dunXDei4REb1syGJR/rH/3rYe3PYm24cCk6haCYcM9XUDHWKI+EDfN8f2VNtTx48fv9X5RkTEwIYsFrY3Ac9IetH2fIntXwA3UY01PFK6liiva8tmq4H9WnabBDxc4pMGiEdERIc06Yb6FbBM0mXlSqSLJF1Ut5Ok8ZL2LOu7A/8Z+DGwgOp53pTXa8v6AmC6pN3Ko1unALeVrqr1ko4uV0Gd1rJPRER0QJP7LK4ry9aaAMwrVzTtBMy3/S1Ji4H5ks4AHgROBrC9QtJ84G5gI3BWadkAnAnMBXYHri9L2ww11XdERC9qMpHgvNIy2N/2vU0PXCYbPGyA+KPAcYPsMwuYNUC8DxhqvCMiItqoyUSC/wVYSvVsCyQdKmlBm/OKiIgu0mTM4nzgKOAXALaXAge0LaOIiOg6TYrFRttP9IsNeOlqRESMTk0GuJdLehcwRtIU4Gzgh+1NKyIiukmTlsWHqeZr2gB8DXgS+Egbc4qIiC7T5GqoZ4BPlIce2fb69qcVERHdpMnVUEdKWgbcRXVz3r9KOqL9qUVERLdoMmZxGfBB298HkHQM1QORXt3OxCIions0GbNYv7lQANi+BUhXVEREDxm0ZSHp8LJ6m6QvUg1uG3gn1aSAERHRI4bqhvr7fu8/1bKe+ywiInrIoMXC9hs7mUhERHSv2gHuMs34acDk1u1tn922rCIioqs0uRrq28CPgGXAs+1NJyIiulGTYvE823/W9kwiIqJrNbl09iuS/ljSBEnjNi9tzywiIrpGk5bFr4HPAp/gd1dBGTiwXUlFRER3aVIs/gz4Pds/b3cyMXKGepTsqtkndDCTiOhGTbqhVgDPtDuRiIjoXk1aFpuApZJupJqmHMilsxERvaRJsfhmWSIiokc1eZ7FvE4kEhER3avJHdwPMMBcULZzNVRERI9o0g01tWX9ecDJQO6ziIjoIbVXQ9l+tGX5me0LgTfV7SdpP0k3SrpH0gpJ55T4OEkLJd1XXvdq2ec8SSsl3Svp+Jb4EZKWlc8ukqRtO92IiNgWTR6renjLMlXSnwB7NDj2RuBc268EjgbOknQQMBNYZHsKsKi8p3w2HTgYmAZcLGlMOdYlwAxgSlmmbc1JRkTE9mnSDdX6XIuNwCrglLqdbK8B1pT19ZLuASYCJwLHls3mUT1I6c9L/GrbG4AHJK0EjpK0ChhrezGApCuAk4DrG+QeERHDoMnVUNv9XAtJk4HDgFuBfUshwfYaSfuUzSZSzW672eoS+01Z7x8f6HtmULVA2H///bc37YiIKJpcDbUb8F/Z8nkWf93kCyS9EPg68BHbTw4x3DDQBx4ivmXQngPMAZg6dWqe5hcRMUyadENdCzwBLKHlDu4mJO1CVSiutP2NEn5E0oTSqpgArC3x1cB+LbtPAh4u8UkDxCMiokOaFItJtrd6QLlcsXQZcI/tC1o+WgCcDswur9e2xK+SdAHwEqqB7Ntsb5K0XtLRVN1YpwGf39p8IiJi2zUpFj+U9Crby7by2K8D3gMsk7S0xP6CqkjMl3QG8CDVfRvYXiFpPnA31UD6WbY3lf3OBOYCu1MNbGdwOyKig5oUi2OA95Y7uTdQjSHY9quH2sn2LQw83gBw3CD7zAJmDRDvAw5pkGtERLRBk2Lx1rZnERERXa3JpbM/7UQiERHRvZo8/CgiInpcikVERNRKsYiIiFopFhERUSvFIiIiaqVYRERErRSLiIiolWIRERG1UiwiIqJWikVERNRKsYiIiFopFhERUavJrLMRQ5o887ohP181+4QOZRIR7ZKWRURE1EqxiIiIWikWERFRK8UiIiJqpVhEREStFIuIiKiVYhEREbVSLCIiolaKRURE1GpbsZD0ZUlrJS1viY2TtFDSfeV1r5bPzpO0UtK9ko5viR8haVn57CJJalfOERExsHa2LOYC0/rFZgKLbE8BFpX3SDoImA4cXPa5WNKYss8lwAxgSln6HzMiItqsbcXC9s3AY/3CJwLzyvo84KSW+NW2N9h+AFgJHCVpAjDW9mLbBq5o2SciIjqk02MW+9peA1Be9ynxicBDLdutLrGJZb1/fECSZkjqk9S3bt26YU08IqKXdcsA90DjEB4iPiDbc2xPtT11/Pjxw5ZcRESv63SxeKR0LVFe15b4amC/lu0mAQ+X+KQB4hER0UGdLhYLgNPL+unAtS3x6ZJ2k3QA1UD2baWrar2ko8tVUKe17BMRER3StocfSfoacCywt6TVwKeA2cB8SWcADwInA9heIWk+cDewETjL9qZyqDOprqzaHbi+LLEDGerhSHkwUsSOoW3Fwvapg3x03CDbzwJmDRDvAw4ZxtQiImIrdcsAd0REdLEUi4iIqJViERERtVIsIiKiVopFRETUSrGIiIhaKRYREVGrbfdZRAyH3NAX0R3SsoiIiFopFhERUSvFIiIiaqVYRERErRSLiIiolauhYtQa6koqyNVUEVsjLYuIiKiVYhEREbVSLCIiolaKRURE1MoAd/SsTCUS0VxaFhERUSvFIiIiaqVYRERErYxZRGyDjHdEr0nLIiIiau0wLQtJ04DPAWOAL9mePcIpRWyTTEMSO6IdolhIGgP8H+DNwGrgdkkLbN89splFDL90cUU32iGKBXAUsNL2/QCSrgZOBFIsIlpsT6slLZ4YimyPdA61JL0DmGb7A+X9e4DX2v5Qv+1mADPK25cD9wJ7Az/vYLrdppfPP+feu3r5/Lf33F9qe3z/4I7SstAAsS2qnO05wJzn7Cj12Z7arsS6XS+ff869N88devv823XuO8rVUKuB/VreTwIeHqFcIiJ6zo5SLG4Hpkg6QNKuwHRgwQjnFBHRM3aIbijbGyV9CPgu1aWzX7a9ouHuc+o3GdV6+fxz7r2rl8+/Lee+QwxwR0TEyNpRuqEiImIEpVhEREStUV0sJE2TdK+klZJmjnQ+nSRplaRlkpZK6hvpfNpN0pclrZW0vCU2TtJCSfeV171GMsd2GeTcz5f0s/L7L5X0hyOZY7tI2k/SjZLukbRC0jkl3iu//WDnP+y//6gdsyhThPwbLVOEAKf2yhQhklYBU233xI1Jkt4APAVcYfuQEvtfwGO2Z5f/LOxl+89HMs92GOTczweesv13I5lbu0maAEywfYekPYAlwEnAe+mN336w8z+FYf79R3PL4rdThNj+NbB5ipAYhWzfDDzWL3wiMK+sz6P6SzTqDHLuPcH2Gtt3lPX1wD3ARHrntx/s/IfdaC4WE4GHWt6vpk1/iF3KwA2SlpRpUHrRvrbXQPWXCthnhPPptA9Juqt0U43KbphWkiYDhwG30oO/fb/zh2H+/UdzsWg0Rcgo9jrbhwNvBc4qXRXROy4BXgYcCqwB/n5Es2kzSS8Evg58xPaTI51Ppw1w/sP++4/mYtHTU4TYfri8rgWuoeqW6zWPlD7dzX27a0c4n46x/YjtTbafBS5lFP/+knah+ofyStvfKOGe+e0HOv92/P6juVj07BQhkl5QBruQ9ALgLcDyofcalRYAp5f104FrRzCXjtr8D2Xxdkbp7y9JwGXAPbYvaPmoJ377wc6/Hb//qL0aCqBcLnYhv5siZNbIZtQZkg6kak1ANaXLVaP93CV9DTiWanrmR4BPAd8E5gP7Aw8CJ9sedQPBg5z7sVRdEAZWAf99cx/+aCLpGOD7wDLg2RL+C6p++1747Qc7/1MZ5t9/VBeLiIgYHqO5GyoiIoZJikVERNRKsYiIiFopFhERUSvFIiIiaqVYxA5P0lNtOOahrTN1llk8P7odxzu5zAx64/BkuM15rJK090jmEDumFIuIgR0KDOe03mcAH7T9xmE8ZkTHpFjEqCLpY5JuLxOofbrEJpf/1V9a5vy/QdLu5bMjy7aLJX1W0vJyx/9fA+8szwJ4Zzn8QZJuknS/pLMH+f5Ty3NElkv6TIn9FXAM8AVJn+23/QRJN5fvWS7p9SV+iaS+ku+nW7ZfJel/lnz7JB0u6buSfiLpT8o2x5ZjXiPpbklfkLTF33VJ75Z0W/nuL0oaU5a5JZdlkv50O3+SGC1sZ8myQy9U8/ZDNa3JHKpJJHcCvgW8AZgMbAQOLdvNB95d1pcD/6mszwaWl/X3Av/Q8h3nAz8EdqO6U/pRYJd+ebyE6m7h8VR3zv8/4KTy2U1Uzxfpn/u5wCfK+hhgj7I+riV2E/Dq8n4VcGZZ/9/AXcAe5TvXlvixwK+AA8v+C4F3tOy/N/BK4J83nwNwMXAacASwsCW/PUf6983SHUtaFjGavKUsdwJ3AK8AppTPHrC9tKwvASZL2pPqH+cflvhVNce/zvYGVw+UWgvs2+/zI4GbbK+zvRG4kqpYDeV24H3lYUWvcvVMAoBTJN1RzuVg4KCWfTbPcbYMuNX2etvrgF+VcwK4zdWzXDYBX6Nq2bQ6jqow3C5paXl/IHA/cKCkz0uaBvTcDK4xsJ1HOoGIYSTgb21/8TnBap7/DS2hTcDuDDyN/VD6H6P/35+tPR62by7Tx58AfKV0U30f+ChwpO3HJc0FnjdAHs/2y+nZlpz6z+PT/72AebbP65+TpNcAxwNnUT1x7f1be14x+qRlEaPJd4H3l7n9kTRR0qAPvbH9OLBe0tElNL3l4/VU3Ttb41bgDyTtreqxvqcC/zLUDpJeStV9dCnV7KGHA2OBp4EnJO1L9UySrXVUmXF5J+CdwC39Pl8EvGPzn4+qZ1a/tFwptZPtrwN/WfKJSMsiRg/bN0h6JbC4mrmZp4B3U7UCBnMGcKmkp6nGBp4o8RuBmaWL5m8bfv8aSeeVfQV823bd1NjHAh+T9JuS72m2H5B0J7CCqlvoB02+v5/FVGMwrwJu5nezEG/O9W5Jn6R6muJOwG+oWhK/BC5vGRDfouURvSmzzkZPk/RC20+V9ZnABNvnjHBa20XSscBHbb9thFOJUSQti+h1J5TWwM7AT6mugoqIftKyiIiIWhngjoiIWikWERFRK8UiIiJqpVhEREStFIuIiKj171t6x1H9fHi7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 하이퍼파라미터 조정을 위한 길이 분포 출력\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af882f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 21567\n",
      "                                                Text                Summary\n",
      "0  bought several vitality canned dog food produc...  good quality dog food\n",
      "1  product arrived labeled jumbo salted peanuts p...      not as advertised\n",
      "2  confection around centuries light pillowy citr...    delight says it all\n",
      "3  looking secret ingredient robitussin believe f...         cough medicine\n",
      "4  great taffy great price wide assortment yummy ...            great taffy\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 : 텍스트 길이 = 평균보다 약간 큰 값으로 결정\n",
    "text_max_len = 50\n",
    "summary_max_len = 8\n",
    "\n",
    "# Text 및 Summary 길이가 위에 정한 최대 길이보다 큰 샘플들 제거\n",
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1826bf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text                Summary  \\\n",
      "0  bought several vitality canned dog food produc...  good quality dog food   \n",
      "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
      "2  confection around centuries light pillowy citr...    delight says it all   \n",
      "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
      "4  great taffy great price wide assortment yummy ...            great taffy   \n",
      "\n",
      "                    decoder_input                  decoder_target  \n",
      "0  sostoken good quality dog food  good quality dog food eostoken  \n",
      "1      sostoken not as advertised      not as advertised eostoken  \n",
      "2    sostoken delight says it all    delight says it all eostoken  \n",
      "3         sostoken cough medicine         cough medicine eostoken  \n",
      "4            sostoken great taffy            great taffy eostoken  \n"
     ]
    }
   ],
   "source": [
    "# seq2seq 학습을 위해 디코더 입력 및 레이블에 시작 토큰과 종료 토큰 추가\n",
    "# 시작 토큰 'sostoken', 종료 토큰 'eostoken'을 사용하고 문장 앞뒤에 추가\n",
    "# 요약 데이터에 시작 토큰과 종료 토큰 추가\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "print(data.head())\n",
    "\n",
    "# 인코더의 입력, 그리고 토큰 추가된 디코더의 입력 및 레이블을 각각 저장\n",
    "encoder_input = np.array(data['Text'])\n",
    "decoder_input = np.array(data['decoder_input'])\n",
    "decoder_target = np.array(data['decoder_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01f135ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13464  5041  3181 ...  8471 17048  1318]\n",
      "테스트 데이터의 수 : 4313\n",
      "훈련 데이터의 개수 : 17254\n",
      "훈련 레이블의 개수 : 17254\n",
      "테스트 데이터의 개수 : 4313\n",
      "테스트 레이블의 개수 : 4313\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 테스트 데이터를 분리\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "\n",
    "# 랜덤하게 섞인 데이터를 8:2의 비율로\n",
    "# 훈련 데이터와 테스트 데이터로 분리\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28e4e223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[313, 577, 335, 37, 55, 150, 431, 469, 1982, 255, 63, 504, 537, 471, 240, 648, 297, 242, 9, 122, 1], [67, 47, 32, 45, 111, 1316, 63, 34, 1015], [7, 203, 643, 263, 418, 573, 1897, 14, 8, 38, 159, 240, 471, 159, 48, 37, 1296, 32, 677, 48, 197, 110, 196, 71, 1130, 800, 91, 43, 1093, 3128, 193, 9, 212, 573, 2568, 432, 218, 1897, 4206, 2, 121, 237], [2, 16, 191, 3945, 1450, 3685, 5608, 2083, 147, 37, 308, 2036, 5609, 1250, 1, 5610, 415, 241, 1768, 1250, 78, 163, 951, 16, 3492, 4556, 2, 6, 10, 42, 258], [2, 1297, 538, 3, 255, 737, 446, 547, 2, 99, 1530, 115, 415, 2, 367, 2142, 29]]\n",
      "[[1, 171, 195, 1311], [1, 48, 226, 351, 4], [1, 9, 501, 817], [1, 25, 80], [1, 3, 227]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 벡터화\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(src_vocab)\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)\n",
    "\n",
    "encoded_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoded_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "print(encoded_input_train[:5])\n",
    "\n",
    "# 요약 시퀀스를 정수 시퀀스로 변환\n",
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(tar_vocab)\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "decoded_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoded_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoded_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoded_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "print(decoded_input_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0a741e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소스 단어 집합(vocabulary)의 크기 : 18295\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 13740\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 4555\n",
      "단어 집합에서 희귀 단어의 비율: 75.10248701831101\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.249031157960006\n",
      "타겟 단어 집합(vocabulary)의 크기 : 5655\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 4099\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 1556\n",
      "단어 집합에서 희귀 단어의 비율: 72.48452696728559\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 7.532919451144767\n"
     ]
    }
   ],
   "source": [
    "# 참고 : 등장 빈도수가 7회 미만인 단어들이 얼만큼의 비중을 차지하는지 확인\n",
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받음\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작을경우\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('소스 단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받음\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작을경우\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('타겟 단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9662560d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 17254\n",
      "훈련 레이블의 개수 : 17254\n",
      "테스트 데이터의 개수 : 4313\n",
      "테스트 레이블의 개수 : 4313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4454: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    }
   ],
   "source": [
    "# 만약 전체 데이터에서 빈도수가 낮은 단어들을 삭제했을 경우\n",
    "# 빈도수가 낮은 단어만으로 구성되었던 샘플들은 빈(empty) 샘플이 됨\n",
    "# 요약문의 경우 sostoken, eostoken이 추가됨, 빈 요약문의 실질적 길이는 1\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoded_input_train = np.delete(encoded_input_train, drop_train, axis=0)\n",
    "decoded_input_train = np.delete(decoded_input_train, drop_train, axis=0)\n",
    "decoded_target_train = np.delete(decoded_target_train, drop_train, axis=0)\n",
    "\n",
    "encoded_input_test = np.delete(encoded_input_test, drop_test, axis=0)\n",
    "decoded_input_test = np.delete(decoded_input_test, drop_test, axis=0)\n",
    "decoded_target_test = np.delete(decoded_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoded_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoded_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoded_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoded_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a697d6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 313  577  335   37   55  150  431  469 1982  255   63  504  537  471\n",
      "   240  648  297  242    9  122    1    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  67   47   32   45  111 1316   63   34 1015    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   7  203  643  263  418  573 1897   14    8   38  159  240  471  159\n",
      "    48   37 1296   32  677   48  197  110  196   71 1130  800   91   43\n",
      "  1093 3128  193    9  212  573 2568  432  218 1897 4206    2  121  237\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   2   16  191 3945 1450 3685 5608 2083  147   37  308 2036 5609 1250\n",
      "     1 5610  415  241 1768 1250   78  163  951   16 3492 4556    2    6\n",
      "    10   42  258    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   2 1297  538    3  255  737  446  547    2   99 1530  115  415    2\n",
      "   367 2142   29    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "[[   1  171  195 1311    0    0    0    0]\n",
      " [   1   48  226  351    4    0    0    0]\n",
      " [   1    9  501  817    0    0    0    0]\n",
      " [   1   25   80    0    0    0    0    0]\n",
      " [   1    3  227    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이에 맞추어 훈련 데이터와 테스트 데이터에 대해서 패딩 작업을 수행\n",
    "encoded_input_train = pad_sequences(encoded_input_train, maxlen = text_max_len, padding='post')\n",
    "encoded_input_test = pad_sequences(encoded_input_test, maxlen = text_max_len, padding='post')\n",
    "decoded_input_train = pad_sequences(decoded_input_train, maxlen = summary_max_len, padding='post')\n",
    "decoded_target_train = pad_sequences(decoded_target_train, maxlen = summary_max_len, padding='post')\n",
    "decoded_input_test = pad_sequences(decoded_input_test, maxlen = summary_max_len, padding='post')\n",
    "decoded_target_test = pad_sequences(decoded_target_test, maxlen = summary_max_len, padding='post')\n",
    "\n",
    "print(encoded_input_train[:5])\n",
    "print(decoded_input_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32bc6ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# 디코더의 출력층 : 어텐션을 사용하지 않을경우\\ndecoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\\ndecoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \\n\\n# 모델 정의\\nmodel = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\\nmodel.summary()\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더 설계 : LSTM 층 3개\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])\n",
    "\n",
    "'''\n",
    "# 디코더의 출력층 : 어텐션을 사용하지 않을경우\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e61ffb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 50, 128)      1024000     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 50, 256),    394240      ['embedding[0][0]']              \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 50, 256),    525312      ['lstm[0][0]']                   \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 128)    256000      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 50, 256),    525312      ['lstm_1[0][0]']                 \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 256),  394240      ['embedding_1[0][0]',            \n",
      "                                 (None, 256),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 256)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " attention_layer (AttentionLaye  ((None, None, 256),  131328     ['lstm_2[0][0]',                 \n",
      " r)                              (None, None, 50))                'lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, None, 512)    0           ['lstm_3[0][0]',                 \n",
      "                                                                  'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 2000)   1026000     ['concat_layer[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,276,432\n",
      "Trainable params: 4,276,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# importing attention layer (바다나우 어텐션)\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "class AttentionLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층 : 어텐션을 사용 할 경우\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3d3ad43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 772s 11s/step - loss: 2.8168 - val_loss: 2.4787\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# patience 옵션을 2로 설정 : 모델 학습 시 성능이 개선되지 않는 횟수가 2회를 초과하면 학습을 멈춤\n",
    "earlystop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoded_input_train, decoded_input_train], y = decoded_target_train, \\\n",
    "          validation_data = ([encoded_input_test, decoded_input_test], decoded_target_test), \\\n",
    "          batch_size = 256, callbacks=[earlystop], epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce0ce2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9256408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 용 seq2seq + attention 요약 모델\n",
    "# seq2seq는 훈련 단계와 테스트 단계의 동작이 다르므로 테스트 단계의 모델을 별도로 다시 설계할 필요가 있음\n",
    "\n",
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용, 이는 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c1c955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : chili recipe great find husband loved easy make liked recommend \n",
      "실제 요약문 : we loved this chili recipe \n",
      "예측 요약문 :  great\n",
      "\n",
      "\n",
      "원문 : several relatives dietary restrictions family including gluten dairy sensitivity happy try pamela oat chocolate chip coconut snack bars taste good well balanced chocolate coconut flavors pleasant moist consistency similar oat bars tried since gluten dairy free everyone family enjoy without worrying effects update like much reorder family friends recommended cfh \n",
      "실제 요약문 : very good tasting snack bars recommended \n",
      "예측 요약문 :  great\n",
      "\n",
      "\n",
      "원문 : look tasty candy freak try say least extremely dissapointed chemical taste texture like chewing glue nasty would never eat buy goes flavors \n",
      "실제 요약문 : \n",
      "예측 요약문 :  great\n",
      "\n",
      "\n",
      "원문 : made potato bread great results hodgson bread mix way dry needs moisture buy unless want really dry bread \n",
      "실제 요약문 : potato bread \n",
      "예측 요약문 :  great\n",
      "\n",
      "\n",
      "원문 : dog love busy buddy bottle fill dog food treats spends lots time floor get treats eat rope top right away put bottle helps block top things harder get great toy cocker spaniel \n",
      "실제 요약문 : great toy \n",
      "예측 요약문 :  great\n",
      "\n",
      "\n",
      "원문 : great deal agree best right amount hot tough taste great \n",
      "실제 요약문 : beef sticks \n",
      "예측 요약문 :  great\n",
      "\n",
      "\n",
      "원문 : realize getting packets chips happy see arrived love anything sweet potato opened box eagerly started delicious concern really like texture anything popped flavor delicious overlook chips would work perfectly many diet plans crispy although real chips satisfy urge something crunchy going buy several flavors keep hand \n",
      "실제 요약문 : these are scrumptious \n",
      "예측 요약문 :  great\n",
      "\n",
      "\n",
      "원문 : received coffee time promised paul newman coffee fantastic rich robust flavor buy \n",
      "실제 요약문 : coffee \n",
      "예측 요약문 :  great\n",
      "\n",
      "\n",
      "원문 : loved flavor fact long lasting everyone office eats eat half stick sitting around big gum far able gum flavor like bright citrus taste overpowering love like minty gum go mint chocolate chip flavor gum \n",
      "실제 요약문 : awesome taste \n",
      "예측 요약문 :  great\n",
      "\n",
      "\n",
      "원문 : weeks pregnant worst case heartburn indigestion sick till mom found tea first day drank cups symptoms bit continued using day heartburn indigestion day still going strong feeling better ever thank god moms tea \n",
      "실제 요약문 : it works \n",
      "예측 요약문 :  great\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "\n",
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    sentence=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            sentence = sentence + src_index_to_word[i]+' '\n",
    "    return sentence\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    sentence=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            sentence = sentence + tar_index_to_word[i] + ' '\n",
    "    return sentence\n",
    "\n",
    "# 테스트 샘플 중 100번부터 110번까지 실제/예측 요약문 비교\n",
    "for i in range(100, 110):\n",
    "    print(\"원문 :\",seq2text(encoded_input_test[i]))\n",
    "    print(\"실제 요약문 :\",seq2summary(decoded_input_test[i]))\n",
    "    print(\"예측 요약문 :\",decode_sequence(encoded_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a00970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecb7c258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52e580335864979a8034f12a62beb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0c38822bcf406dafd3ba2ce0573054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6ed40ff8204ec083d4f15c9eb67926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f0920c4c0e459e9854ed0eade03678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb5d2eccb424edeba815fa788c26a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef549b047cb4c0697b01a4dc96e3a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some input text for summarization.\n"
     ]
    }
   ],
   "source": [
    "# ChatGPT : Please write the sample code using bart model in keras.\n",
    "# Sure, here's some sample code using the BART model in Keras:\n",
    "from transformers import BartTokenizer, TFBartForConditionalGeneration\n",
    "\n",
    "# Load the tokenizer and BART model\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "model = TFBartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "\n",
    "# Define your input text and encode it using the tokenizer\n",
    "input_text = \"Some input text for summarization.\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='tf')\n",
    "\n",
    "# Generate a summary using the BART model\n",
    "summary_ids = model.generate(input_ids)\n",
    "\n",
    "# Decode the summary and print it\n",
    "summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT : How to fine-tune the model in additinal to the above code?\n",
    "'''\n",
    "To fine-tune a BART model, you can follow the same approach as with any other transformer model. Here's a high-level overview of the steps:\n",
    "\n",
    "Load the pre-trained BART model using transformers.BartForConditionalGeneration.\n",
    "Prepare your data by tokenizing your text and converting it to input features that the model can process.\n",
    "Fine-tune the model on your task-specific data using Keras' model.fit method or custom training loop.\n",
    "Evaluate the fine-tuned model on a validation set to check its performance.\n",
    "Here's some sample code that fine-tunes a pre-trained BART model on a summarization task:\n",
    "'''\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load pre-trained BART model\n",
    "model = transformers.BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "\n",
    "# Prepare data\n",
    "tokenizer = transformers.BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "\n",
    "train_texts = ['train text 1', 'train text 2', ...]\n",
    "train_summaries = ['train summary 1', 'train summary 2', ...]\n",
    "\n",
    "val_texts = ['val text 1', 'val text 2', ...]\n",
    "val_summaries = ['val summary 1', 'val summary 2', ...]\n",
    "\n",
    "max_length = 1024\n",
    "\n",
    "# Preparing the data by tokenizing the input and summary texts using transformers.\n",
    "# BartTokenizer and converting them to input features that the model can process.\n",
    "train_encodings = tokenizer(train_texts, train_summaries, truncation=True, max_length=max_length)\n",
    "val_encodings = tokenizer(val_texts, val_summaries, truncation=True, max_length=max_length)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_encodings['input_ids']\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_encodings['input_ids']\n",
    "))\n",
    "\n",
    "# Fine-tune the model\n",
    "optimizer = transformers.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_dataset.shuffle(10000).batch(8), epochs=3, batch_size=16,\n",
    "    validation_data = val_dataset.shuffle(10000).batch(16),\n",
    ")\n",
    "\n",
    "# Evaluate the fine-tuned model\n",
    "model.evaluate(val_dataset.shuffle(10000).batch(16))\n",
    "\n",
    "# Save the model in HDF5 format\n",
    "model.save('fine_tuned_bart.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11847325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT : How to get the predicted result in additinal to the above code?\n",
    "# To get the predicted results after fine-tuning the BART model in the above,\n",
    "# you can use the predict method of the Keras model. Here's an example:\n",
    "\n",
    "# Assume that you have fine-tuned the BART model and saved it as `fine_tuned_bart.h5`\n",
    "# Load the fine-tuned BART model\n",
    "model = TFBartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "model.load_model('fine_tuned_bart.h5')\n",
    "\n",
    "# Assume that you have a list of input texts named `input_texts`\n",
    "# Convert the input texts into features using the tokenizer\n",
    "inputs = tokenizer.batch_encode_plus(input_texts, return_tensors='tf', padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Get the model predictions\n",
    "outputs = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "\n",
    "# Decode the model predictions back into text\n",
    "output_texts = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

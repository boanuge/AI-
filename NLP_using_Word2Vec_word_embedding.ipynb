{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2e1b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 워드 임베딩\n",
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from lxml import etree\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3db1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 및 필요 파일 다운로드\n",
    "'''\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")\n",
    "'''\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00dfa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수 : 11737\n",
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
      "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
      "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 전처리\n",
    "\n",
    "targetXML = open('ted_en-20160408_trimmed.xml', 'r', encoding='UTF8')\n",
    "target_text = etree.parse(targetXML)\n",
    "\n",
    "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져옴\n",
    "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
    "\n",
    "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는\n",
    "# (Audio), (Laughter) 등의 배경음 부분을 제거\n",
    "# 아래 코드는 괄호로 구성된 내용을 제거\n",
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
    "\n",
    "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행\n",
    "sent_text = sent_tokenize(content_text)\n",
    "\n",
    "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환\n",
    "normalized_text = []\n",
    "for string in sent_text:\n",
    "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
    "     normalized_text.append(tokens)\n",
    "\n",
    "# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행\n",
    "result = [word_tokenize(sentence) for sentence in normalized_text]\n",
    "\n",
    "print('총 샘플의 개수 : {}'.format(len(result)))\n",
    "\n",
    "# 샘플 3개만 출력\n",
    "for line in result[:3]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f9c16f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Word2Vec 하이퍼파라미터값\n",
    "# vector_size = 워드 벡터의 특징 값 (임베딩 된 벡터의 차원)\n",
    "# window = 컨텍스트 윈도우 크기\n",
    "# min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않음)\n",
    "# workers = 학습을 위한 프로세스 수\n",
    "# sg = 0은 CBOW, 1은 Skip-gram\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = Word2Vec(sentences=result, vector_size=100, window=5, min_count=5, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc339fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3538, 100)\n",
      "[('woman', 0.9966552257537842), ('guy', 0.9956862926483154), ('called', 0.9954178333282471), ('week', 0.9952705502510071), ('dead', 0.9949605464935303), ('later', 0.9948659539222717), ('written', 0.9947954416275024), ('internship', 0.9946897029876709), ('mother', 0.9946314692497253), ('cycle', 0.9946281909942627)]\n"
     ]
    }
   ],
   "source": [
    "# 완성된 임베딩 매트릭스의 크기 확인\n",
    "print(model.wv.vectors.shape)\n",
    "\n",
    "model_result = model.wv.most_similar(\"man\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de4c6e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.9966552257537842), ('guy', 0.9956862926483154), ('called', 0.9954178333282471), ('week', 0.9952705502510071), ('dead', 0.9949605464935303), ('later', 0.9948659539222717), ('written', 0.9947954416275024), ('internship', 0.9946897029876709), ('mother', 0.9946314692497253), ('cycle', 0.9946281909942627)]\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec 모델 저장 및 로드\n",
    "\n",
    "model.wv.save_word2vec_format('wod2vec_model_for_en.h5') # 모델 저장\n",
    "loaded_model = KeyedVectors.load_word2vec_format(\"wod2vec_model_for_en.h5\") # 모델 로드\n",
    "\n",
    "model_result = loaded_model.most_similar(\"man\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92071e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 워드 임베딩\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcdb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 다운로드\n",
    "'''\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50cf6957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                           document  label\n",
      "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
      "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
      "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
      "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
      "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1\n",
      "10000\n",
      "False\n",
      "False\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 전처리\n",
    "\n",
    "train_data = pd.read_table('ratings_trimmed.txt')\n",
    "print(train_data[:5]) # 상위 5개 출력\n",
    "print(len(train_data)) # 리뷰 개수 출력\n",
    "\n",
    "# NULL 값 존재 유무 (존재할 경우 제거 후 다시 리뷰 개수 출력)\n",
    "print(train_data.isnull().values.any())\n",
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인\n",
    "print(len(train_data)) # 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f37ac6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18989/1109759143.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "100%|██████████| 10000/10000 [00:30<00:00, 332.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['어리다', '때', '보고', '지금', '다시', '보다', '재밌다', 'ㅋㅋ'], ['디자인', '을', '배우다', '학생', '외국', '디자이너', '그', '일군', '전통', '을', '통해', '발전', '문화', '산업', '부럽다', '사실', '우리나라', '에서도', '그', '어렵다', '시절', '끝', '까지', '열정', '을', '지키다', '노라노', '같다', '전통', '있다', '저', '같다', '사람', '꿈', '을', '꾸다', '이루다', '나가다', '수', '있다', '것', '감사하다'], ['폴리스스토리', '시리즈', '부터', '뉴', '까지', '버리다', '하나', '없다', '최고'], ['오다', '연기', '진짜', '개', '쩔다', '지루하다', '생각', '몰입', '보다', '그렇다', '이렇다', '진짜', '영화', '지'], ['안개', '자욱하다', '밤하늘', '뜨다', '있다', '초승달', '같다', '영화']]\n",
      "리뷰의 최대 길이 : 61\n",
      "리뷰의 평균 길이 : 10.3893\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정규 표현식을 통한 한글 외 문자 제거\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "\n",
    "# 불용어 정의\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "# 형태소 분석기 OKT를 사용한 토큰화 작업 (다소 시간 소요)\n",
    "okt = Okt()\n",
    "\n",
    "tokenized_data = []\n",
    "for sentence in tqdm(train_data['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    tokenized_data.append(stopwords_removed_sentence)\n",
    "\n",
    "print(tokenized_data[:5]) # 상위 5개 출력\n",
    "\n",
    "# 리뷰 길이 분포 확인\n",
    "print('리뷰의 최대 길이 :',max(len(review) for review in tokenized_data))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, tokenized_data))/len(tokenized_data))\n",
    "plt.hist([len(review) for review in tokenized_data], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f0e3de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2448, 100)\n",
      "[('크다', 0.9995489716529846), ('캐릭터', 0.9995301365852356), ('여자', 0.9994693398475647), ('부분', 0.9994571805000305), ('특히', 0.999456524848938), ('앞', 0.9994545578956604), ('그리고', 0.9994537234306335), ('뿐', 0.9994500279426575), ('시키다', 0.9994356036186218), ('그래도', 0.9994270205497742)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences = tokenized_data, vector_size = 100, window = 5, min_count = 5, workers = 4, sg = 0)\n",
    "\n",
    "# 완성된 임베딩 매트릭스의 크기 확인\n",
    "print(model.wv.vectors.shape)\n",
    "\n",
    "print(model.wv.most_similar(\"남자\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c4423bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 훈련된 Word2Vec 임베딩(Pre-trained Word2Vec embedding) 사용\n",
    "import gensim\n",
    "\n",
    "# 구글의 사전 훈련된 Word2Vec 모델을 로드 : 모델 파일 사이즈 약 1.7G-Bytes\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "366de146",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000000, 300)\n",
      "[ 0.11279297 -0.02612305 -0.04492188  0.06982422  0.140625    0.03039551\n",
      " -0.04370117  0.24511719  0.08740234 -0.05053711  0.23144531 -0.07470703\n",
      "  0.21875     0.03466797 -0.14550781  0.05761719  0.00671387 -0.00701904\n",
      "  0.13183594 -0.25390625  0.14355469 -0.140625   -0.03564453 -0.21289062\n",
      " -0.24804688  0.04980469 -0.09082031  0.14453125  0.05712891 -0.10400391\n",
      " -0.19628906 -0.20507812 -0.27539062  0.03063965  0.20117188  0.17382812\n",
      "  0.09130859 -0.10107422  0.22851562 -0.04077148  0.02709961 -0.00106049\n",
      "  0.02709961  0.34179688 -0.13183594 -0.078125    0.02197266 -0.18847656\n",
      " -0.17480469 -0.05566406 -0.20898438  0.04858398 -0.07617188 -0.15625\n",
      " -0.05419922  0.01672363 -0.02722168 -0.11132812 -0.03588867 -0.18359375\n",
      "  0.28710938  0.01757812  0.02185059 -0.05664062 -0.01251221  0.01708984\n",
      " -0.21777344 -0.06787109  0.04711914 -0.00668335  0.08544922 -0.02209473\n",
      "  0.31835938  0.01794434 -0.02246094 -0.03051758 -0.09570312  0.24414062\n",
      "  0.20507812  0.05419922  0.29101562  0.03637695  0.04956055 -0.06689453\n",
      "  0.09277344 -0.10595703 -0.04370117  0.19726562 -0.03015137  0.05615234\n",
      "  0.08544922 -0.09863281 -0.02392578 -0.08691406 -0.22460938 -0.16894531\n",
      "  0.09521484 -0.0612793  -0.03015137 -0.265625   -0.13378906  0.00139618\n",
      "  0.01794434  0.10107422  0.13964844  0.06445312 -0.09765625 -0.11376953\n",
      " -0.24511719 -0.15722656  0.00457764  0.12988281 -0.03540039 -0.08105469\n",
      "  0.18652344  0.03125    -0.09326172 -0.04760742  0.23730469  0.11083984\n",
      "  0.08691406  0.01916504  0.21386719 -0.0065918  -0.08984375 -0.02502441\n",
      " -0.09863281 -0.05639648 -0.26757812  0.19335938 -0.08886719 -0.25976562\n",
      "  0.05957031 -0.10742188  0.09863281  0.1484375   0.04101562  0.00340271\n",
      " -0.06591797 -0.02941895  0.20019531 -0.00521851  0.02355957 -0.13671875\n",
      " -0.12597656 -0.10791016  0.0067749   0.15917969  0.0145874  -0.15136719\n",
      "  0.07519531 -0.02905273  0.01843262  0.20800781  0.25195312 -0.11523438\n",
      " -0.23535156  0.04101562 -0.11035156  0.02905273  0.22460938 -0.04272461\n",
      "  0.09667969  0.11865234  0.08007812  0.07958984  0.3125     -0.14941406\n",
      " -0.234375    0.06079102  0.06982422 -0.14355469 -0.05834961 -0.36914062\n",
      " -0.10595703  0.00738525  0.24023438 -0.10400391 -0.02124023  0.05712891\n",
      " -0.11621094 -0.16894531 -0.06396484 -0.12060547  0.08105469 -0.13769531\n",
      " -0.08447266  0.12792969 -0.15429688  0.17871094  0.2421875  -0.06884766\n",
      "  0.03320312  0.04394531 -0.04589844  0.03686523 -0.07421875 -0.01635742\n",
      " -0.24121094 -0.08203125 -0.01733398  0.0291748   0.10742188  0.11279297\n",
      "  0.12890625  0.01416016 -0.28710938  0.16503906 -0.25585938  0.2109375\n",
      " -0.19238281  0.22363281  0.04541016  0.00872803  0.11376953  0.375\n",
      "  0.09765625  0.06201172  0.12109375 -0.24316406  0.203125    0.12158203\n",
      "  0.08642578  0.01782227  0.17382812  0.01855469  0.03613281 -0.02124023\n",
      " -0.02905273 -0.04541016  0.1796875   0.06494141 -0.13378906 -0.09228516\n",
      "  0.02172852  0.02099609  0.07226562  0.3046875  -0.27539062 -0.30078125\n",
      "  0.08691406 -0.22949219  0.0546875  -0.34179688 -0.00680542 -0.0291748\n",
      " -0.03222656  0.16210938  0.01141357  0.23339844 -0.0859375  -0.06494141\n",
      "  0.15039062  0.17675781  0.08251953 -0.26757812 -0.11669922  0.01330566\n",
      "  0.01818848  0.10009766 -0.09570312  0.109375   -0.16992188 -0.23046875\n",
      " -0.22070312  0.0625      0.03662109 -0.125       0.05151367 -0.18847656\n",
      "  0.22949219  0.26367188 -0.09814453  0.06176758  0.11669922  0.23046875\n",
      "  0.32617188  0.02038574 -0.03735352 -0.12255859  0.296875   -0.25\n",
      " -0.08544922 -0.03149414  0.38085938  0.02929688 -0.265625    0.42382812\n",
      " -0.1484375   0.14355469 -0.03125     0.00717163 -0.16601562 -0.15820312\n",
      "  0.03637695 -0.16796875 -0.01483154  0.09667969 -0.05761719 -0.00515747]\n",
      "0.050600607\n",
      "0.36346263\n",
      "0.1263805\n",
      "[('tome', 0.7485828995704651), ('books', 0.7379177808761597), ('memoir', 0.7302926778793335), ('paperback_edition', 0.6868364214897156), ('autobiography', 0.6741527915000916), ('memoirs', 0.6505153179168701), ('Book', 0.6479281783103943), ('paperback', 0.6471226811408997), ('novels', 0.6341459155082703), ('hardback', 0.6283079981803894)]\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_model.vectors.shape)\n",
    "\n",
    "print(word2vec_model['book'])\n",
    "\n",
    "print(word2vec_model.similarity('book', 'man'))\n",
    "print(word2vec_model.similarity('book', 'paper'))\n",
    "print(word2vec_model.similarity('book', 'medicine'))\n",
    "\n",
    "print(word2vec_model.most_similar(\"book\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1b48d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no GPU to use.\n",
      " @ CDT(2023-06-02T11:13:47.953221)\n",
      "Create YOLOv3 model with 9 anchors and 1 classes.\n",
      "WARNING:tensorflow:Skipping loading weights for layer #249 (named conv2d_58) due to mismatch in shape for weight conv2d_58/kernel:0. Weight expects shape (1, 1, 1024, 18). Received saved weight with shape (255, 1024, 1, 1)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #249 (named conv2d_58) due to mismatch in shape for weight conv2d_58/bias:0. Weight expects shape (18,). Received saved weight with shape (255,)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #250 (named conv2d_66) due to mismatch in shape for weight conv2d_66/kernel:0. Weight expects shape (1, 1, 512, 18). Received saved weight with shape (255, 512, 1, 1)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #250 (named conv2d_66) due to mismatch in shape for weight conv2d_66/bias:0. Weight expects shape (18,). Received saved weight with shape (255,)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #251 (named conv2d_74) due to mismatch in shape for weight conv2d_74/kernel:0. Weight expects shape (1, 1, 256, 18). Received saved weight with shape (255, 256, 1, 1)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #251 (named conv2d_74) due to mismatch in shape for weight conv2d_74/bias:0. Weight expects shape (18,). Received saved weight with shape (255,)\n",
      "Load weights yolo3_weights_via_MSCOCO.h5.\n",
      "Freeze the first 185 layers of total 252 layers.\n",
      "Train on 1719 samples, val on 191 samples, with batch size 32.\n",
      "Train the model @ CDT(2023-06-02T11:13:55.492271)\n",
      "Epoch 1/100\n",
      " 3/53 [>.............................] - ETA: 33:52 - loss: 5899.0103 "
     ]
    }
   ],
   "source": [
    "# Only CPU 약 하루 걸림 @ 테스트 서버\n",
    "\n",
    "model_path = 'yolo3_trained_1910_epoch_100.h5'\n",
    "\n",
    "annotation_path = './yolo_train.txt'\n",
    "classes_path = './yolo_classes.txt'\n",
    "anchors_path = './yolo_anchors.txt'\n",
    "\n",
    "import os # Protocol Buffers to use Python rather than C++\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "## GPU에 할당(사용)되는 메모리 크기 제한\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "gpu_memory_limit=1024*12 # only allocate 12GB of memory on the gpus[0], i.e. first GPU\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=gpu_memory_limit)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(\"GPU memory allocation(\",gpu_memory_limit,\")\",\n",
    "          \"# of Physical GPU(\",len(gpus),\") # of Logical GPU(\",len(logical_gpus),\")\")\n",
    "  except RuntimeError as e:\n",
    "    print(e) # Virtual devices must be set before GPUs have been initialized\n",
    "else:\n",
    "   print(\"There is no GPU to use.\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./\")\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from yolo3_model_for_training import preprocess_true_boxes, yolo_body, yolo_loss, get_random_data\n",
    "\n",
    "# Print the current date and time in the format:\n",
    "# \"YYYY-MM-DD HH:MM:SS.microseconds\"\n",
    "import datetime\n",
    "def print_current_datetime(text=\"\"):\n",
    "    datetime_string = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    print(\"{} @ CDT({})\".format(text,datetime_string))\n",
    "\n",
    "print_current_datetime()\n",
    "\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True,\n",
    "freeze_body=1, weights_path='yolo3_weights_via_MSCOCO.h5'): # Full filtering\n",
    "#freeze_body=2, weights_path='yolo3_weights_via_MSCOCO.h5'):\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "\n",
    "\n",
    "def get_classes(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "class_names = get_classes(classes_path)\n",
    "num_classes = len(class_names)\n",
    "anchors = get_anchors(anchors_path)\n",
    "\n",
    "input_shape = (416,416) # multiple of 32, hw\n",
    "\n",
    "model = create_model(input_shape, anchors, num_classes)\n",
    "\n",
    "val_split = 0.1\n",
    "with open(annotation_path) as f:\n",
    "    lines = f.readlines()\n",
    "np.random.seed(10101)\n",
    "np.random.shuffle(lines)\n",
    "np.random.seed(None)\n",
    "num_val = int(len(lines)*val_split)\n",
    "num_train = len(lines) - num_val\n",
    "\n",
    "# Adjust learning rate (use default Adam) to avoid \"Gradient Explosion\"\n",
    "model.compile(optimizer=Adam(), loss={ # Removing learning_rate because of gradient explosion\n",
    "    'yolo_loss': lambda y_true, y_pred: y_pred}) # use custom yolo_loss Lambda layer.\n",
    "\n",
    "batch_size = 32\n",
    "print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "\n",
    "print_current_datetime(\"Train the model\")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "history = model.fit(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "        steps_per_epoch=max(1, num_train//batch_size),\n",
    "        validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "        validation_steps=max(1, num_val//batch_size),\n",
    "        epochs=100,\n",
    "        initial_epoch=0,\n",
    "        verbose=1,\n",
    "        callbacks=[reduce_lr, early_stopping])\n",
    "\n",
    "print_current_datetime(\"Save the model\")\n",
    "\n",
    "model.save(model_path)\n",
    "\n",
    "print_current_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec85b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b+', label='Validation val_loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb6cab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

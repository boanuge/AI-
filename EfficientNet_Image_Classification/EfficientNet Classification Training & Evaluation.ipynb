{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672dc731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze last 100 layers for fine-tuning, which was 20 layers in the previous trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f901c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet-B7 achieves new state-of-the-art 84.4% top-1 / 97.1% top-5 accuracy year 2019 while being 8.4x\n",
    "# smaller than the best existing CNN, e.g. EfficientNet-B1 is 7.6x smaller and 5.7x faster than ResNet-152.\n",
    "# We are using EfficientNet-B5 to make the computing process faster and it's more efficient in our case.\n",
    "# https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/\n",
    "# https://ai.googleblog.com/2019/05/efficientnet-improving-accuracy-and.html\n",
    "\n",
    "# Print the current date and time in the format:\n",
    "# \"YYYY-MM-DD HH:MM:SS.microseconds\"\n",
    "import datetime\n",
    "def print_current_datetime():\n",
    "    datetime_string = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    print(\"CDT(Current Date and Time):\", datetime_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c97384e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 10:30:52.817788: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-29 10:30:52.817844: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/gbike/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDT(Current Date and Time): 2023-03-29 10:30:55.478954\n",
      "Found 24 images belonging to 3 classes.\n",
      "Found 6 images belonging to 3 classes.\n",
      "Data shape: (2, 456, 456, 3)\n",
      "Labels shape: (2, 3)\n",
      "Min pixel value: 0.0\n",
      "Max pixel value: 1.0\n",
      "Class indices: {'class1': 0, 'class2': 1, 'class3': 2}\n",
      "Class names: ['class1', 'class2', 'class3']\n",
      "CDT(Current Date and Time): 2023-03-29 10:30:55.505328\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "print_current_datetime()\n",
    "\n",
    "# Dataset directory hierarchy structure\n",
    "'''\n",
    "dataset/\n",
    "    train/\n",
    "        class1/\n",
    "            img1.jpg\n",
    "            img2.jpg\n",
    "            ...\n",
    "        class2/\n",
    "            img1.jpg\n",
    "            img2.jpg\n",
    "            ...\n",
    "        class3/\n",
    "            img1.jpg\n",
    "            img2.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        class1/\n",
    "            img1.jpg\n",
    "            img2.jpg\n",
    "            ...\n",
    "        class2/\n",
    "            img1.jpg\n",
    "            img2.jpg\n",
    "            ...\n",
    "        class3/\n",
    "            img1.jpg\n",
    "            img2.jpg\n",
    "            ...\n",
    "'''\n",
    "\n",
    "# Configuration : EfficientNetB5\n",
    "path_train = 'dataset/train'\n",
    "path_validation = 'dataset/validation'\n",
    "img_height = 456\n",
    "img_width = 456\n",
    "\n",
    "# Create an instance of the ImageDataGenerator class\n",
    "train_datagen_ins = ImageDataGenerator(rescale=1/255)\n",
    "val_datagen_ins = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# The ImageDataGenerator class will automatically load the images\n",
    "# and generate one-hot encoded labels based on the directories.\n",
    "\n",
    "# Load the training data and labels from a directory\n",
    "train_generator = train_datagen_ins.flow_from_directory(\n",
    "    path_train,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=2, # 64 preferred (depending on the dataset size)\n",
    "    class_mode='categorical',\n",
    "    #class_mode=\"binary\" # The labels are binary (either 0 or 1)\n",
    ")\n",
    "\n",
    "val_generator = val_datagen_ins.flow_from_directory(\n",
    "    path_validation,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=2, # 64 preferred (depending on the dataset size)\n",
    "    class_mode='categorical',\n",
    "    #class_mode=\"binary\" # The labels are binary (either 0 or 1)\n",
    ")\n",
    "\n",
    "# Get a batch of data from the train_generator\n",
    "X_batch, y_batch = next(train_generator)\n",
    "\n",
    "# Check the shape of the data and labels\n",
    "print('Data shape:', X_batch.shape)\n",
    "print('Labels shape:', y_batch.shape)\n",
    "\n",
    "# Check the range of pixel values\n",
    "print('Min pixel value:', X_batch.min())\n",
    "print('Max pixel value:', X_batch.max())\n",
    "\n",
    "# Check the class indices and class names\n",
    "print('Class indices:', train_generator.class_indices)\n",
    "print('Class names:', list(train_generator.class_indices.keys()))\n",
    "\n",
    "print_current_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2231060",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDT(Current Date and Time): 2023-03-29 10:30:59.450895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 10:30:59.828417: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-29 10:30:59.828448: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-29 10:30:59.828466: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-255-120-161): /proc/driver/nvidia/version does not exist\n",
      "2023-03-29 10:30:59.828653: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Trainable parameters:\n",
      "tf.Tensor(29391411, shape=(), dtype=int32)\n",
      "Non-trainable parameters:\n",
      "tf.Tensor(172743, shape=(), dtype=int32)\n",
      "CDT(Current Date and Time): 2023-03-29 10:31:07.278361\n",
      "Trainable parameters:\n",
      "tf.Tensor(1050627, shape=(), dtype=int32)\n",
      "Non-trainable parameters:\n",
      "tf.Tensor(28513527, shape=(), dtype=int32)\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 62s 3s/step - loss: 1.1174 - accuracy: 0.2917\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 40s 3s/step - loss: 1.0743 - accuracy: 0.4583\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 35s 3s/step - loss: 1.0496 - accuracy: 0.5417\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 38s 3s/step - loss: 1.0248 - accuracy: 0.5833\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 39s 3s/step - loss: 0.9436 - accuracy: 0.6250\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.9859 - accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 39s 3s/step - loss: 0.8658 - accuracy: 0.6667\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 44s 4s/step - loss: 0.8637 - accuracy: 0.6667\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.9129 - accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 38s 3s/step - loss: 0.8940 - accuracy: 0.6250\n",
      "CDT(Current Date and Time): 2023-03-29 10:38:04.721523\n",
      "Trainable parameters:\n",
      "tf.Tensor(6079619, shape=(), dtype=int32)\n",
      "Non-trainable parameters:\n",
      "tf.Tensor(23484535, shape=(), dtype=int32)\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 41s 4s/step - loss: 0.8907 - accuracy: 0.5417 - val_loss: 1.1144 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.8229 - accuracy: 0.6667 - val_loss: 1.1160 - val_accuracy: 0.3333\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 40s 3s/step - loss: 0.7707 - accuracy: 0.7083 - val_loss: 1.1165 - val_accuracy: 0.3333\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.6861 - accuracy: 0.7917 - val_loss: 1.1199 - val_accuracy: 0.3333\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 40s 3s/step - loss: 0.6961 - accuracy: 0.7917 - val_loss: 1.1309 - val_accuracy: 0.3333\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6847 - accuracy: 0.7917Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.6847 - accuracy: 0.7917 - val_loss: 1.1382 - val_accuracy: 0.3333\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbike/anaconda3/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDT(Current Date and Time): 2023-03-29 10:41:58.162852\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print_current_datetime()\n",
    "\n",
    "# Load the pre-trained model\n",
    "base_model = load_model('efficientnet-b5-pretrained-on-imagenet.h5')\n",
    "\n",
    "# Add custom layers for classification\n",
    "# for 3 different classes to classify\n",
    "base_model_output = base_model.output\n",
    "base_model_output = GlobalAveragePooling2D()(base_model_output)\n",
    "base_model_output = Dense(512, activation='relu')(base_model_output)\n",
    "base_model_output = Dropout(0.5)(base_model_output)\n",
    "predictions = Dense(3, activation='softmax')(base_model_output)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "#model.summary()\n",
    "\n",
    "# Print trainable and non-trainable parameters\n",
    "print(\"Trainable parameters:\")\n",
    "print(tf.reduce_sum([tf.reduce_prod(w.shape) for w in model.trainable_weights]))\n",
    "print(\"Non-trainable parameters:\")\n",
    "print(tf.reduce_sum([tf.reduce_prod(w.shape) for w in model.non_trainable_weights]))\n",
    "\n",
    "print_current_datetime()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "# Compile the model and freeze the base model layers\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print trainable and non-trainable parameters\n",
    "print(\"Trainable parameters:\")\n",
    "print(tf.reduce_sum([tf.reduce_prod(w.shape) for w in model.trainable_weights]))\n",
    "print(\"Non-trainable parameters:\")\n",
    "print(tf.reduce_sum([tf.reduce_prod(w.shape) for w in model.non_trainable_weights]))\n",
    "\n",
    "# Train the model on new layers for few epochs\n",
    "model.fit(train_generator, epochs=10, verbose=1)\n",
    "\n",
    "print_current_datetime()\n",
    "\n",
    "# Compile the model and unfreeze some of the base model layers and continue training\n",
    "#for layer in base_model.layers[-20:]:\n",
    "for layer in base_model.layers[-100:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Print trainable and non-trainable parameters\n",
    "print(\"Trainable parameters:\")\n",
    "print(tf.reduce_sum([tf.reduce_prod(w.shape) for w in model.trainable_weights]))\n",
    "print(\"Non-trainable parameters:\")\n",
    "print(tf.reduce_sum([tf.reduce_prod(w.shape) for w in model.non_trainable_weights]))\n",
    "\n",
    "# 모델 학습 시 성능이 개선되지 않는 횟수가 5회를 초과하면 학습을 멈춤\n",
    "earlystop_callback = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(train_generator,\n",
    "          validation_data=val_generator,\n",
    "          callbacks=[earlystop_callback],\n",
    "          epochs = 100,\n",
    "          verbose=1)\n",
    "\n",
    "model.save('efficientnet_finetuned_earlystop_epochs.h5')\n",
    "\n",
    "print_current_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b357002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epochs = range(1,len(loss)+1)\n",
    "\n",
    "plt.plot(epochs,acc,'bo',label = 'Training Accuracy')\n",
    "plt.plot(epochs,val_acc,'b',label = 'Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,loss,'bo',label = 'Training loss')\n",
    "plt.plot(epochs,val_loss,'b',label = 'Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb8c9e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "[[0.35329908 0.3011299  0.345571  ]]\n",
      "Cat\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "model_loaded = load_model('efficientnet_finetuned_earlystop_epochs.h5')\n",
    "\n",
    "img_path = 'image1.jpg'\n",
    "img_resized = tf.keras.preprocessing.image.load_img(img_path, target_size=(456, 456)) # EfficientNetB5\n",
    "img_vectorized = tf.keras.preprocessing.image.img_to_array(img_resized)\n",
    "img_vectorized = tf.keras.applications.efficientnet.preprocess_input(img_vectorized)\n",
    "img_vectorized = np.expand_dims(img_vectorized, axis=0)\n",
    "\n",
    "predicted_result = model_loaded.predict(img_vectorized)\n",
    "print(predicted_result)\n",
    "\n",
    "# Get the predicted label name: class1(0), class2(1), class3(2)\n",
    "label_map = {0: \"Cat\", 1: \"Dog\", 2: \"Human\"}\n",
    "predicted_label_id = np.argmax(predicted_result)\n",
    "predicted_label_name = label_map[predicted_label_id]\n",
    "\n",
    "print(predicted_label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10a55f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "Found 6 files belonging to 3 classes.\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.0312 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nOutput:\\nFound 6 files belonging to 3 classes.\\n1/1 [==============================] - 6s 6s/step - loss: 1.0312 - accuracy: 0.5000\\n[1.031218409538269, 0.5]\\n\\nComments:\\nEvaluation on 6 images belonging to 3 classes\\nThe loss value and accuracy of the model on this batch\\nwere calculated as 1.0312 and 0.5, respectively.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Load the model\n",
    "model_loaded = load_model('efficientnet_finetuned_earlystop_2023-03-29.h5')\n",
    "\n",
    "# Load the data\n",
    "'''\n",
    "directory: the directory where the images are stored.\n",
    "labels: specifies how to infer the labels of the images.\n",
    "The value 'inferred' means the labels will be automatically\n",
    "inferred from the subdirectories of the main directory.\n",
    "'''\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    directory='dataset/validation',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(456, 456))\n",
    "\n",
    "# Evaluate the model\n",
    "model_loaded.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_loaded.evaluate(test_dataset, verbose=1)\n",
    "\n",
    "'''\n",
    "Output:\n",
    "Found 6 files belonging to 3 classes.\n",
    "1/1 [==============================] - 6s 6s/step - loss: 1.0312 - accuracy: 0.5000\n",
    "[1.031218409538269, 0.5]\n",
    "\n",
    "Comments:\n",
    "Evaluation on 6 images belonging to 3 classes\n",
    "The loss value and accuracy of the model on this batch\n",
    "were calculated as 1.0312 and 0.5, respectively.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87948024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "Found 6 images belonging to 3 classes.\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.0053 - accuracy: 0.8333\n",
      "Test loss: 1.005331039428711\n",
      "Test accuracy: 0.8333333134651184\n",
      "Confusion matrix:\n",
      "tf.Tensor(\n",
      "[[2 0 0]\n",
      " [0 2 0]\n",
      " [0 1 1]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the model\n",
    "model_loaded = load_model('efficientnet_finetuned_earlystop_2023-03-29.h5')\n",
    "\n",
    "# Create an ImageDataGenerator for test set\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'dataset/validation',\n",
    "        target_size=(456, 456),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, acc = model_loaded.evaluate(test_generator, verbose=1)\n",
    "\n",
    "# Predict the classes of test images\n",
    "y_pred = model_loaded.predict(test_generator)\n",
    "\n",
    "# Get the true classes of test images\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = tf.math.confusion_matrix(y_true, tf.argmax(y_pred, axis=1))\n",
    "\n",
    "# Print metrics\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc)\n",
    "print('Confusion matrix:')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58aca2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images belonging to 3 classes.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "6/6 [==============================] - 4s 196ms/step - loss: 1.1144 - accuracy: 0.3333\n",
      "Test loss: 1.114362359046936\n",
      "Test accuracy: 0.3333333432674408\n",
      "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n",
      "[0 0 1 1 2 2]\n",
      "Confusion matrix:\n",
      "tf.Tensor(\n",
      "[[2 0 0]\n",
      " [2 0 0]\n",
      " [2 0 0]], shape=(3, 3), dtype=int32)\n",
      "[keras] Precision: 0.0\n",
      "[keras] Recall: 0.0\n",
      "[keras] F1 score: nan\n",
      "[sklearn] Precision: 0.1111111111111111\n",
      "[sklearn] Recall: 0.3333333333333333\n",
      "[sklearn] F1 score: 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbike/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the test dataset\n",
    "test_data_dir = 'dataset/validation'\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_data_gen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(456, 456),\n",
    "    batch_size=1, # Precision, Recall, and F1-score may vary by this value.\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load the trained model\n",
    "model_loaded = tf.keras.models.load_model('efficientnet_finetuned_earlystop_2023-03-29.h5')\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "eval_results = model_loaded.evaluate(test_generator)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Test loss:\", eval_results[0])\n",
    "print(\"Test accuracy:\", eval_results[1])\n",
    "\n",
    "# Predict the class labels for the test dataset\n",
    "y_pred = model_loaded.predict(test_generator)\n",
    "y_pred = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get the true class labels for the test dataset\n",
    "y_true = test_generator.classes\n",
    "\n",
    "print(y_pred)\n",
    "print(y_true)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_mtx)\n",
    "\n",
    "'''\n",
    "In Keras, precision and recall are calculated as streaming metrics.\n",
    "This means that they accumulate values across multiple batches and take\n",
    "the average of these values to calculate the final precision and recall.\n",
    "This is useful when you are working with large datasets\n",
    "that cannot be loaded into memory all at once.\n",
    "'''\n",
    "\n",
    "# Compute and print precision and recall\n",
    "precision = tf.keras.metrics.Precision()\n",
    "precision.update_state(y_true, y_pred)\n",
    "print(\"[keras] Precision:\", precision.result().numpy())\n",
    "\n",
    "recall = tf.keras.metrics.Recall()\n",
    "recall.update_state(y_true, y_pred)\n",
    "print(\"[keras] Recall:\", recall.result().numpy())\n",
    "\n",
    "f1_score = 2*((precision.result()*recall.result())/(precision.result()+recall.result()))\n",
    "print(\"[keras] F1 score:\", f1_score.numpy())\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "'''\n",
    "On the other hand, in scikit-learn, precision and recall are calculated on the entire dataset at once.\n",
    "This means that there is a need having enough memory to load the entire dataset into memory.\n",
    "\n",
    "The average parameter is set to 'weighted' in order to compute the weighted average\n",
    "precision, recall, and F1 score. The weighted average takes into account the number\n",
    "of samples in each class and can provide a better metric for imbalanced datasets.\n",
    "The number of samples that the weighted average takes into account depends on\n",
    "the distribution of samples across the classes. Classes with more samples\n",
    "will have a higher weight and contribute more to the overall score.\n",
    "'''\n",
    "\n",
    "s_precision = precision_score(y_true, y_pred, average='weighted')\n",
    "s_recall = recall_score(y_true, y_pred, average='weighted')\n",
    "s_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(\"[sklearn] Precision:\", s_precision)\n",
    "print(\"[sklearn] Recall:\", s_recall)\n",
    "print(\"[sklearn] F1 score:\", s_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
